# .github/workflows/ci.yml
# Comprehensive CI pipeline for ML training framework

name: CI Pipeline

on:
  push:
    branches: [main, develop, feature/*]
  pull_request:
    branches: [main, develop]
  schedule:
    - cron: "0 2 * * 1" # Weekly on Monday at 2 AM

env:
  PYTHON_VERSION: "3.11"
  POETRY_VERSION: "1.6.1"
  NODE_VERSION: "18"

jobs:
  # Code quality and linting
  quality:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements-dev.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements-dev.txt

      - name: Run Black formatting check
        run: black --check --diff .

      - name: Run isort import sorting check
        run: isort --check-only --diff .

      - name: Run flake8 linting
        run: flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics

      - name: Run mypy type checking
        run: mypy . --ignore-missing-imports

      - name: Run bandit security check
        run: bandit -r . -x tests/ -f json -o bandit-report.json

      - name: Upload bandit results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: bandit-report
          path: bandit-report.json

  # Unit and integration tests
  test:
    name: Tests
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.9", "3.10", "3.11"]
        exclude:
          - os: windows-latest
            python-version: "3.9"
          - os: macos-latest
            python-version: "3.9"

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-${{ matrix.python-version }}-pip-${{ hashFiles('requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-${{ matrix.python-version }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
          pip install -e .

      - name: Run pytest with coverage
        run: |
          pytest --cov=. --cov-report=xml --cov-report=html --junitxml=pytest.xml -v

      - name: Upload coverage to Codecov
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          flags: unittests
          name: codecov-${{ matrix.os }}-${{ matrix.python-version }}

      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results-${{ matrix.os }}-${{ matrix.python-version }}
          path: |
            pytest.xml
            htmlcov/

  # GPU tests (if available)
  test-gpu:
    name: GPU Tests
    runs-on: [self-hosted, gpu]
    if: contains(github.event.head_commit.message, '[gpu-test]')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install CUDA dependencies
        run: |
          pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Run GPU tests
        run: |
          python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
          pytest tests/test_gpu/ -v --gpu

  # Documentation build
  docs:
    name: Documentation
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install -r requirements-dev.txt
          pip install mkdocs mkdocs-material

      - name: Build documentation
        run: mkdocs build --strict

      - name: Deploy documentation to GitHub Pages
        if: github.ref == 'refs/heads/main'
        run: mkdocs gh-deploy --force

  # Docker build and test
  docker:
    name: Docker Build
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and test Docker image
        run: |
          docker build -f docker/Dockerfile -t ml-training:test .
          docker run --rm ml-training:test python -c "import torch; print('Docker build successful')"

      - name: Build and push Docker image
        if: github.ref == 'refs/heads/main'
        uses: docker/build-push-action@v5
        with:
          context: .
          file: docker/Dockerfile
          push: true
          tags: |
            ghcr.io/${{ github.repository }}:latest
            ghcr.io/${{ github.repository }}:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # Security scanning
  security:
    name: Security Scan
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: "fs"
          scan-ref: "."
          format: "sarif"
          output: "trivy-results.sarif"

      - name: Upload Trivy scan results
        uses: github/codeql-action/upload-sarif@v2
        with:
          sarif_file: "trivy-results.sarif"

      - name: Run CodeQL analysis
        uses: github/codeql-action/init@v2
        with:
          languages: python

      - name: Autobuild
        uses: github/codeql-action/autobuild@v2

      - name: Perform CodeQL analysis
        uses: github/codeql-action/analyze@v2

  # Performance benchmarks
  benchmark:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
          pip install pytest-benchmark

      - name: Run benchmarks
        run: |
          pytest tests/benchmarks/ --benchmark-json=benchmark.json

      - name: Store benchmark results
        uses: benchmark-action/github-action-benchmark@v1
        with:
          tool: "pytest"
          output-file-path: benchmark.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true

  # Model validation
  model-validation:
    name: Model Validation
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Download test models
        run: |
          mkdir -p models/test
          python scripts/download_test_models.py

      - name: Validate model architectures
        run: |
          python -m validation.validate_models

      - name: Run model tests
        run: |
          pytest tests/test_models/ -v

  # Data validation
  data-validation:
    name: Data Validation
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install great-expectations pandas-profiling

      - name: Run data validation
        run: |
          python scripts/validate_data.py

  # Integration tests
  integration:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [test, docker]
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 3s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Run integration tests
        env:
          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379/0
        run: |
          pytest tests/integration/ -v

  # Deployment readiness
  deploy-ready:
    name: Deployment Readiness
    runs-on: ubuntu-latest
    needs: [quality, test, docs, docker, security, integration]
    if: github.ref == 'refs/heads/main'
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check deployment readiness
        run: |
          echo "✅ All checks passed - Ready for deployment"
          echo "🐳 Docker image built and pushed"
          echo "📚 Documentation updated"
          echo "🔒 Security scans completed"
          echo "🧪 All tests passing"

      - name: Create deployment artifact
        run: |
          echo "DEPLOY_TAG=${{ github.sha }}" > deploy.env
          echo "DEPLOY_TIME=$(date -u +%Y-%m-%dT%H:%M:%SZ)" >> deploy.env
          echo "DEPLOY_BRANCH=${{ github.ref_name }}" >> deploy.env

      - name: Upload deployment artifact
        uses: actions/upload-artifact@v3
        with:
          name: deployment-info
          path: deploy.env

  # Notification
  notify:
    name: Notifications
    runs-on: ubuntu-latest
    needs: [deploy-ready]
    if: always()
    steps:
      - name: Notify Slack on success
        if: needs.deploy-ready.result == 'success'
        uses: 8398a7/action-slack@v3
        with:
          status: success
          fields: repo,message,commit,author,action,eventName,ref,workflow
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

      - name: Notify Slack on failure
        if: needs.deploy-ready.result == 'failure'
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          fields: repo,message,commit,author,action,eventName,ref,workflow
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
