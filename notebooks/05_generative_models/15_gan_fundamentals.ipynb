{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa86530",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks: From Theory to Advanced Architectures\n",
    "\n",
    "**Complete Implementation and Analysis of GANs including Vanilla GAN, DCGAN, and WGAN-GP**\n",
    "\n",
    "**Authors:** Deep Learning Research Team  \n",
    "**Institution:** Advanced AI Research Institute  \n",
    "**Course:** Deep Generative Models and Computer Vision  \n",
    "**Date:** December 2024\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook provides a comprehensive implementation and analysis of Generative Adversarial Networks (GANs), covering fundamental concepts, multiple architectures, training dynamics, and evaluation metrics. We explore the adversarial training paradigm through hands-on implementation of Vanilla GAN, Deep Convolutional GAN (DCGAN), and Wasserstein GAN with Gradient Penalty (WGAN-GP).\n",
    "\n",
    "## Key Objectives\n",
    "1. Understand the mathematical foundations and theory behind adversarial training\n",
    "2. Implement multiple GAN architectures from scratch with detailed analysis\n",
    "3. Master GAN training techniques, stability issues, and best practices\n",
    "4. Explore latent space properties and interpolation capabilities\n",
    "5. Analyze training dynamics and compare different GAN variants\n",
    "6. Implement comprehensive evaluation metrics for generative models\n",
    "7. Build production-ready image generation systems\n",
    "\n",
    "## 1. Setup and Environment Configuration\n",
    "\n",
    "```python\n",
    "# Import required libraries for comprehensive GAN implementation\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting environment\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# Set device and seeds for reproducibility\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üé® Generative Adversarial Networks Implementation\")\n",
    "print(f\"   Device: {device}\")\n",
    "print(f\"   PyTorch Version: {torch.__version__}\")\n",
    "print(f\"   CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "manual_seed = 42\n",
    "random.seed(manual_seed)\n",
    "torch.manual_seed(manual_seed)\n",
    "np.random.seed(manual_seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(manual_seed)\n",
    "    torch.cuda.manual_seed_all(manual_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(\"‚úÖ Environment configured with deterministic settings\")\n",
    "\n",
    "# Create results directory structure\n",
    "notebook_results_dir = Path('results/gans/fundamentals')\n",
    "notebook_results_dir.mkdir(parents=True, exist_ok=True)\n",
    "(notebook_results_dir / 'generated_images').mkdir(exist_ok=True)\n",
    "(notebook_results_dir / 'models').mkdir(exist_ok=True)\n",
    "(notebook_results_dir / 'analysis').mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Results will be saved to: {notebook_results_dir}\")\n",
    "```\n",
    "\n",
    "## 2. GAN Theory and Mathematical Foundations\n",
    "\n",
    "Understanding the adversarial training paradigm and core mathematical concepts behind GANs.\n",
    "\n",
    "```python\n",
    "class GANTheoryAnalyzer:\n",
    "    \"\"\"\n",
    "    Comprehensive analysis and visualization of GAN theory and concepts.\n",
    "    \n",
    "    This class provides tools for understanding:\n",
    "    - Adversarial training dynamics\n",
    "    - Mathematical objectives and game theory\n",
    "    - Training stability and convergence\n",
    "    - Distribution alignment visualization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.fig_size = (16, 12)\n",
    "        \n",
    "    def explain_gan_mathematics(self):\n",
    "        \"\"\"Provide detailed explanation of GAN mathematical foundations.\"\"\"\n",
    "        print(\"üéØ GAN MATHEMATICAL FOUNDATIONS\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        print(\"\\nüìê Core Minimax Game Formulation:\")\n",
    "        print(\"   min max V(D,G) = E[log D(x)] + E[log(1 - D(G(z)))]\")\n",
    "        print(\"    G   D\")\n",
    "        \n",
    "        print(\"\\nüé≤ Component Breakdown:\")\n",
    "        print(\"   ‚Ä¢ D(x): Discriminator's probability that x comes from real data\")\n",
    "        print(\"   ‚Ä¢ G(z): Generator's output given random noise z\")\n",
    "        print(\"   ‚Ä¢ E[¬∑]: Expected value over the respective data distributions\")\n",
    "        print(\"   ‚Ä¢ x ~ p_data(x): Samples from real data distribution\")\n",
    "        print(\"   ‚Ä¢ z ~ p_z(z): Samples from noise distribution (usually Gaussian)\")\n",
    "        \n",
    "        print(\"\\nüéØ Individual Training Objectives:\")\n",
    "        print(\"   Discriminator Goal: max E[log D(x)] + E[log(1 - D(G(z)))]\")\n",
    "        print(\"   Generator Goal:     max E[log D(G(z))] (or min E[log(1 - D(G(z)))])\")\n",
    "        \n",
    "        print(\"\\n‚öñÔ∏è Nash Equilibrium Analysis:\")\n",
    "        print(\"   ‚Ä¢ Optimal discriminator: D*(x) = p_data(x) / (p_data(x) + p_g(x))\")\n",
    "        print(\"   ‚Ä¢ At equilibrium when p_g = p_data: D*(x) = 1/2 everywhere\")\n",
    "        print(\"   ‚Ä¢ Global minimum: C(G) = -log(4) ‚âà -1.386 when p_g = p_data\")\n",
    "        print(\"   ‚Ä¢ This represents perfect generator that matches real distribution\")\n",
    "        \n",
    "        print(\"\\nüìä Training Dynamics:\")\n",
    "        print(\"   1. Early training: D easily distinguishes real from fake\")\n",
    "        print(\"   2. Middle training: G improves, D performance decreases\")\n",
    "        print(\"   3. Convergence: Both networks reach equilibrium\")\n",
    "        print(\"   4. Ideal outcome: D(real) ‚âà D(fake) ‚âà 0.5\")\n",
    "        \n",
    "    def visualize_adversarial_dynamics(self):\n",
    "        \"\"\"Create comprehensive visualization of GAN training dynamics.\"\"\"\n",
    "        fig, axes = plt.subplots(2, 3, figsize=self.fig_size)\n",
    "        \n",
    "        # 1. Distribution Alignment Over Training\n",
    "        x = np.linspace(-4, 4, 1000)\n",
    "        real_dist = np.exp(-0.5 * (x - 0.5)**2) / np.sqrt(2 * np.pi * 0.5)\n",
    "        fake_dist_early = np.exp(-0.5 * (x + 1.5)**2) / np.sqrt(2 * np.pi * 0.8)\n",
    "        fake_dist_mid = np.exp(-0.5 * (x - 0.1)**2) / np.sqrt(2 * np.pi * 0.7)\n",
    "        fake_dist_late = np.exp(-0.5 * (x - 0.4)**2) / np.sqrt(2 * np.pi * 0.6)\n",
    "        \n",
    "        axes[0, 0].fill_between(x, real_dist, alpha=0.7, label='Real Data (p_data)', color='blue')\n",
    "        axes[0, 0].plot(x, fake_dist_early, '--', label='Generated (Early)', linewidth=2, color='red')\n",
    "        axes[0, 0].plot(x, fake_dist_mid, '-.', label='Generated (Mid)', linewidth=2, color='orange')\n",
    "        axes[0, 0].plot(x, fake_dist_late, '-', label='Generated (Late)', linewidth=2, color='green')\n",
    "        axes[0, 0].set_title('Distribution Alignment During Training')\n",
    "        axes[0, 0].set_xlabel('Value')\n",
    "        axes[0, 0].set_ylabel('Probability Density')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Discriminator Performance Evolution\n",
    "        epochs = np.arange(0, 200, 2)\n",
    "        d_real_acc = 0.5 + 0.45 * np.tanh(epochs / 50)\n",
    "        d_fake_acc = 0.95 - 0.45 * np.tanh(epochs / 80)\n",
    "        \n",
    "        axes[0, 1].plot(epochs, d_real_acc, label='D(real data) accuracy', linewidth=2, color='blue')\n",
    "        axes[0, 1].plot(epochs, d_fake_acc, label='D(fake data) accuracy', linewidth=2, color='red')\n",
    "        axes[0, 1].axhline(y=0.5, color='black', linestyle=':', alpha=0.8, label='Random guess (equilibrium)')\n",
    "        axes[0, 1].set_title('Discriminator Performance Over Time')\n",
    "        axes[0, 1].set_xlabel('Training Steps')\n",
    "        axes[0, 1].set_ylabel('Classification Accuracy')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        axes[0, 1].set_ylim(0, 1)\n",
    "        \n",
    "        # 3. Loss Function Visualization\n",
    "        prob = np.linspace(0.001, 0.999, 1000)\n",
    "        d_loss_real = -np.log(prob)\n",
    "        d_loss_fake = -np.log(1 - prob)\n",
    "        g_loss_original = -np.log(prob)\n",
    "        g_loss_alternative = np.log(1 - prob)\n",
    "        \n",
    "        axes[0, 2].plot(prob, d_loss_real, label='D Loss (Real): -log(D(x))', linewidth=2)\n",
    "        axes[0, 2].plot(prob, d_loss_fake, label='D Loss (Fake): -log(1-D(G(z)))', linewidth=2)\n",
    "        axes[0, 2].plot(prob, g_loss_original, label='G Loss: -log(D(G(z)))', linewidth=2)\n",
    "        axes[0, 2].plot(prob, g_loss_alternative, label='G Loss Alt: log(1-D(G(z)))', linewidth=2, linestyle='--')\n",
    "        axes[0, 2].set_title('GAN Loss Functions')\n",
    "        axes[0, 2].set_xlabel('Discriminator Output Probability')\n",
    "        axes[0, 2].set_ylabel('Loss Value')\n",
    "        axes[0, 2].legend()\n",
    "        axes[0, 2].grid(True, alpha=0.3)\n",
    "        axes[0, 2].set_yscale('log')\n",
    "        \n",
    "        # 4. Training Dynamics Simulation\n",
    "        steps = np.arange(0, 300)\n",
    "        base_d_loss = 1.2 * np.exp(-steps / 80) + 0.1\n",
    "        d_loss = base_d_loss + 0.15 * np.sin(steps / 15) * np.exp(-steps / 100)\n",
    "        \n",
    "        base_g_loss = 2.0 * np.exp(-steps / 60) + 0.2\n",
    "        g_loss = base_g_loss + 0.2 * np.sin(steps / 12 + np.pi/4) * np.exp(-steps / 120)\n",
    "        \n",
    "        axes[1, 0].plot(steps, d_loss, label='Discriminator Loss', linewidth=2, color='blue')\n",
    "        axes[1, 0].plot(steps, g_loss, label='Generator Loss', linewidth=2, color='red')\n",
    "        axes[1, 0].set_title('Typical GAN Training Loss Curves')\n",
    "        axes[1, 0].set_xlabel('Training Steps')\n",
    "        axes[1, 0].set_ylabel('Loss Value')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 5. Mode Collapse Illustration\n",
    "        axes[1, 1].hist(np.random.normal(0, 1, 1000), bins=50, alpha=0.7, label='Healthy Generator', density=True)\n",
    "        \n",
    "        collapsed_data = np.concatenate([\n",
    "            np.random.normal(-2, 0.3, 400),\n",
    "            np.random.normal(2, 0.3, 400),\n",
    "            np.random.normal(0, 0.2, 200)\n",
    "        ])\n",
    "        axes[1, 1].hist(collapsed_data, bins=50, alpha=0.7, label='Mode Collapsed Generator', density=True)\n",
    "        axes[1, 1].set_title('Mode Collapse Visualization')\n",
    "        axes[1, 1].set_xlabel('Generated Sample Value')\n",
    "        axes[1, 1].set_ylabel('Density')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 6. Gradient Flow Analysis\n",
    "        d_gradient_norm = 2.0 * np.exp(-steps / 100) + 0.3 + 0.2 * np.random.normal(0, 0.1, len(steps))\n",
    "        g_gradient_norm = 1.8 * np.exp(-steps / 120) + 0.2 + 0.15 * np.random.normal(0, 0.1, len(steps))\n",
    "        \n",
    "        axes[1, 2].plot(steps, d_gradient_norm, label='D Gradient Norm', linewidth=2, alpha=0.8)\n",
    "        axes[1, 2].plot(steps, g_gradient_norm, label='G Gradient Norm', linewidth=2, alpha=0.8)\n",
    "        axes[1, 2].set_title('Gradient Flow During Training')\n",
    "        axes[1, 2].set_xlabel('Training Steps')\n",
    "        axes[1, 2].set_ylabel('Gradient Norm')\n",
    "        axes[1, 2].legend()\n",
    "        axes[1, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(notebook_results_dir / 'analysis' / 'gan_theory_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "# Initialize theory analyzer and run analysis\n",
    "theory_analyzer = GANTheoryAnalyzer()\n",
    "theory_analyzer.explain_gan_mathematics()\n",
    "theory_analyzer.visualize_adversarial_dynamics()\n",
    "\n",
    "print(\"‚úÖ GAN theory analysis completed!\")\n",
    "```\n",
    "\n",
    "## 3. Toy Dataset Implementation and Vanilla GAN\n",
    "\n",
    "Starting with simple 2D datasets to understand GAN fundamentals before moving to complex image generation.\n",
    "\n",
    "```python\n",
    "class ToyDatasetGenerator(Dataset):\n",
    "    \"\"\"\n",
    "    Generate various 2D toy datasets for GAN training and analysis.\n",
    "    \n",
    "    Supports multiple dataset types to test GAN capabilities:\n",
    "    - Gaussian mixtures (multiple modes)\n",
    "    - Spiral patterns (continuous curves)\n",
    "    - Swiss roll (manifold learning)\n",
    "    - Ring patterns (circular distributions)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset_type='gaussian_mixture', num_samples=10000, noise_level=0.1):\n",
    "        self.dataset_type = dataset_type\n",
    "        self.num_samples = num_samples\n",
    "        self.noise_level = noise_level\n",
    "        \n",
    "        self.data = self._generate_data()\n",
    "        \n",
    "        print(f\"üìä Generated {dataset_type} dataset:\")\n",
    "        print(f\"   Samples: {num_samples}\")\n",
    "        print(f\"   Noise level: {noise_level}\")\n",
    "        print(f\"   Data shape: {self.data.shape}\")\n",
    "        \n",
    "    def _generate_data(self):\n",
    "        \"\"\"Generate the specified type of 2D data.\"\"\"\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        if self.dataset_type == 'gaussian_mixture':\n",
    "            # 8 Gaussians arranged in a circle\n",
    "            centers = []\n",
    "            for i in range(8):\n",
    "                angle = 2 * np.pi * i / 8\n",
    "                centers.append([2.5 * np.cos(angle), 2.5 * np.sin(angle)])\n",
    "            \n",
    "            data = []\n",
    "            for _ in range(self.num_samples):\n",
    "                center = centers[np.random.randint(8)]\n",
    "                point = np.random.normal(center, self.noise_level * 2)\n",
    "                data.append(point)\n",
    "                \n",
    "        elif self.dataset_type == 'spiral':\n",
    "            data = []\n",
    "            for i in range(self.num_samples):\n",
    "                t = np.random.uniform(0, 4 * np.pi)\n",
    "                r = t / (4 * np.pi) * 2\n",
    "                \n",
    "                if i % 2 == 0:\n",
    "                    x = r * np.cos(t) + np.random.normal(0, self.noise_level)\n",
    "                    y = r * np.sin(t) + np.random.normal(0, self.noise_level)\n",
    "                else:\n",
    "                    x = -r * np.cos(t) + np.random.normal(0, self.noise_level)\n",
    "                    y = -r * np.sin(t) + np.random.normal(0, self.noise_level)\n",
    "                    \n",
    "                data.append([x, y])\n",
    "                \n",
    "        elif self.dataset_type == 'swiss_roll':\n",
    "            data = []\n",
    "            for _ in range(self.num_samples):\n",
    "                t = np.random.uniform(1.5 * np.pi, 4.5 * np.pi)\n",
    "                x = t * np.cos(t) + np.random.normal(0, self.noise_level * 3)\n",
    "                y = t * np.sin(t) + np.random.normal(0, self.noise_level * 3)\n",
    "                data.append([x/5, y/5])\n",
    "                \n",
    "        return torch.FloatTensor(data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "    def plot_dataset(self, title=None, save_path=None):\n",
    "        \"\"\"Visualize the generated dataset.\"\"\"\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        data_np = self.data.numpy()\n",
    "        \n",
    "        scatter = plt.scatter(data_np[:, 0], data_np[:, 1], alpha=0.6, s=8, c=range(len(data_np)), cmap='viridis')\n",
    "        \n",
    "        if title is None:\n",
    "            title = f'{self.dataset_type.replace(\"_\", \" \").title()} Dataset ({len(self.data)} samples)'\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.xlabel('X coordinate')\n",
    "        plt.ylabel('Y coordinate')\n",
    "        plt.axis('equal')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.colorbar(scatter, label='Sample Index')\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return data_np\n",
    "\n",
    "# Visualize toy datasets\n",
    "print(\"üé® Toy Datasets for GAN Training:\")\n",
    "dataset_types = ['gaussian_mixture', 'spiral', 'swiss_roll']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i, dataset_type in enumerate(dataset_types):\n",
    "    toy_data = ToyDatasetGenerator(dataset_type, num_samples=2000, noise_level=0.1)\n",
    "    data_np = toy_data.data.numpy()\n",
    "    \n",
    "    scatter = axes[i].scatter(data_np[:, 0], data_np[:, 1], alpha=0.6, s=8, c=range(len(data_np)), cmap='viridis')\n",
    "    axes[i].set_title(f'{dataset_type.replace(\"_\", \" \").title()}')\n",
    "    axes[i].set_xlabel('X')\n",
    "    axes[i].set_ylabel('Y')\n",
    "    axes[i].set_aspect('equal')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Toy Datasets for GAN Training', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(notebook_results_dir / 'analysis' / 'toy_datasets_overview.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "class VanillaGenerator(nn.Module):\n",
    "    \"\"\"Vanilla GAN Generator for 2D data generation.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=2, hidden_dim=128, output_dim=2, num_layers=4):\n",
    "        super(VanillaGenerator, self).__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(nn.Linear(latent_dim, hidden_dim))\n",
    "        layers.append(nn.ReLU())\n",
    "        \n",
    "        for _ in range(num_layers - 2):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_dim, output_dim))\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        \"\"\"Forward pass: noise -> generated data.\"\"\"\n",
    "        return self.net(z)\n",
    "\n",
    "class VanillaDiscriminator(nn.Module):\n",
    "    \"\"\"Vanilla GAN Discriminator for 2D data classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=2, hidden_dim=128, num_layers=4):\n",
    "        super(VanillaDiscriminator, self).__init__()\n",
    "        \n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "        layers.append(nn.LeakyReLU(0.2))\n",
    "        \n",
    "        for _ in range(num_layers - 2):\n",
    "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
    "            layers.append(nn.LeakyReLU(0.2))\n",
    "        \n",
    "        layers.append(nn.Linear(hidden_dim, 1))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "        self._init_weights()\n",
    "        \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize network weights.\"\"\"\n",
    "        for module in self.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass: data -> probability of being real.\"\"\"\n",
    "        return self.net(x).squeeze()\n",
    "\n",
    "class VanillaGAN:\n",
    "    \"\"\"Complete Vanilla GAN implementation with comprehensive training and analysis.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=2, data_dim=2, hidden_dim=128, lr=0.0002, beta1=0.5):\n",
    "        self.latent_dim = latent_dim\n",
    "        self.data_dim = data_dim\n",
    "        \n",
    "        # Initialize networks\n",
    "        self.generator = VanillaGenerator(latent_dim, hidden_dim, data_dim).to(device)\n",
    "        self.discriminator = VanillaDiscriminator(data_dim, hidden_dim).to(device)\n",
    "        \n",
    "        # Optimizers\n",
    "        self.g_optimizer = optim.Adam(self.generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "        self.d_optimizer = optim.Adam(self.discriminator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "        \n",
    "        # Loss function\n",
    "        self.criterion = nn.BCELoss()\n",
    "        \n",
    "        # Training history\n",
    "        self.history = {\n",
    "            'g_loss': [], 'd_loss': [], 'real_acc': [], 'fake_acc': [],\n",
    "            'epochs': [], 'generated_samples': []\n",
    "        }\n",
    "        \n",
    "        # Model info\n",
    "        g_params = sum(p.numel() for p in self.generator.parameters())\n",
    "        d_params = sum(p.numel() for p in self.discriminator.parameters())\n",
    "        \n",
    "        print(f\"ü§ñ Vanilla GAN Architecture:\")\n",
    "        print(f\"   Generator parameters: {g_params:,}\")\n",
    "        print(f\"   Discriminator parameters: {d_params:,}\")\n",
    "        print(f\"   Total parameters: {g_params + d_params:,}\")\n",
    "    \n",
    "    def train_step(self, real_data):\n",
    "        \"\"\"Single training step for both networks.\"\"\"\n",
    "        batch_size = real_data.size(0)\n",
    "        \n",
    "        # Create labels\n",
    "        real_labels = torch.ones(batch_size).to(device)\n",
    "        fake_labels = torch.zeros(batch_size).to(device)\n",
    "        \n",
    "        # Train Discriminator\n",
    "        self.d_optimizer.zero_grad()\n",
    "        \n",
    "        real_output = self.discriminator(real_data)\n",
    "        d_loss_real = self.criterion(real_output, real_labels)\n",
    "        \n",
    "        noise = torch.randn(batch_size, self.latent_dim).to(device)\n",
    "        fake_data = self.generator(noise)\n",
    "        fake_output = self.discriminator(fake_data.detach())\n",
    "        d_loss_fake = self.criterion(fake_output, fake_labels)\n",
    "        \n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        self.d_optimizer.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        self.g_optimizer.zero_grad()\n",
    "        \n",
    "        fake_output = self.discriminator(fake_data)\n",
    "        g_loss = self.criterion(fake_output, real_labels)\n",
    "        \n",
    "        g_loss.backward()\n",
    "        self.g_optimizer.step()\n",
    "        \n",
    "        # Calculate accuracies\n",
    "        real_acc = (real_output > 0.5).float().mean().item()\n",
    "        fake_acc = (fake_output < 0.5).float().mean().item()\n",
    "        \n",
    "        return g_loss.item(), d_loss.item(), real_acc, fake_acc\n",
    "    \n",
    "    def train(self, dataloader, num_epochs, save_interval=50, eval_interval=10):\n",
    "        \"\"\"Complete training loop with comprehensive monitoring.\"\"\"\n",
    "        print(f\"üöÄ Training Vanilla GAN for {num_epochs} epochs...\")\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_g_loss = 0\n",
    "            epoch_d_loss = 0\n",
    "            epoch_real_acc = 0\n",
    "            epoch_fake_acc = 0\n",
    "            num_batches = 0\n",
    "            \n",
    "            for real_data in dataloader:\n",
    "                real_data = real_data.to(device)\n",
    "                \n",
    "                g_loss, d_loss, real_acc, fake_acc = self.train_step(real_data)\n",
    "                \n",
    "                epoch_g_loss += g_loss\n",
    "                epoch_d_loss += d_loss\n",
    "                epoch_real_acc += real_acc\n",
    "                epoch_fake_acc += fake_acc\n",
    "                num_batches += 1\n",
    "            \n",
    "            # Calculate averages\n",
    "            avg_g_loss = epoch_g_loss / num_batches\n",
    "            avg_d_loss = epoch_d_loss / num_batches\n",
    "            avg_real_acc = epoch_real_acc / num_batches\n",
    "            avg_fake_acc = epoch_fake_acc / num_batches\n",
    "            \n",
    "            # Store history\n",
    "            self.history['g_loss'].append(avg_g_loss)\n",
    "            self.history['d_loss'].append(avg_d_loss)\n",
    "            self.history['real_acc'].append(avg_real_acc)\n",
    "            self.history['fake_acc'].append(avg_fake_acc)\n",
    "            self.history['epochs'].append(epoch + 1)\n",
    "            \n",
    "            if (epoch + 1) % save_interval == 0:\n",
    "                print(f\"Epoch {epoch+1:3d}/{num_epochs}: \"\n",
    "                      f\"G_Loss={avg_g_loss:.4f}, D_Loss={avg_d_loss:.4f}, \"\n",
    "                      f\"Real_Acc={avg_real_acc:.3f}, Fake_Acc={avg_fake_acc:.3f}\")\n",
    "                \n",
    "                samples = self.generate_samples(1000)\n",
    "                self.history['generated_samples'].append((epoch + 1, samples))\n",
    "            \n",
    "            if (epoch + 1) % eval_interval == 0:\n",
    "                self.plot_generation_progress(epoch + 1)\n",
    "    \n",
    "    def generate_samples(self, num_samples=1000):\n",
    "        \"\"\"Generate samples from the trained generator.\"\"\"\n",
    "        self.generator.eval()\n",
    "        with torch.no_grad():\n",
    "            noise = torch.randn(num_samples, self.latent_dim).to(device)\n",
    "            samples = self.generator(noise)\n",
    "        self.generator.train()\n",
    "        return samples.cpu().numpy()\n",
    "    \n",
    "    def plot_generation_progress(self, epoch, num_samples=1000):\n",
    "        \"\"\"Plot generated samples to track training progress.\"\"\"\n",
    "        samples = self.generate_samples(num_samples)\n",
    "        \n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(samples[:, 0], samples[:, 1], alpha=0.6, s=8, c='red', label='Generated')\n",
    "        plt.title(f'Generated Samples - Epoch {epoch}')\n",
    "        plt.xlabel('X coordinate')\n",
    "        plt.ylabel('Y coordinate')\n",
    "        plt.axis('equal')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.legend()\n",
    "        \n",
    "        save_path = notebook_results_dir / 'generated_images' / f'vanilla_gan_epoch_{epoch}.png'\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        return samples\n",
    "\n",
    "# Train Vanilla GAN on Gaussian Mixture\n",
    "print(\"\\nüéØ Training Vanilla GAN on 2D Gaussian Mixture:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create dataset and dataloader\n",
    "gaussian_dataset = ToyDatasetGenerator('gaussian_mixture', num_samples=5000, noise_level=0.2)\n",
    "gaussian_dataset.plot_dataset(\"Original Gaussian Mixture Dataset\")\n",
    "\n",
    "gaussian_dataloader = DataLoader(gaussian_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "# Initialize and train GAN\n",
    "vanilla_gan = VanillaGAN(latent_dim=2, data_dim=2, hidden_dim=128, lr=0.001)\n",
    "vanilla_gan.train(gaussian_dataloader, num_epochs=200, save_interval=50, eval_interval=25)\n",
    "\n",
    "# Analyze training results\n",
    "def analyze_vanilla_gan_training(gan, real_dataset):\n",
    "    \"\"\"Comprehensive analysis of Vanilla GAN training results.\"\"\"\n",
    "    print(\"\\nüìä Vanilla GAN Training Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss curves\n",
    "    epochs = gan.history['epochs']\n",
    "    axes[0, 0].plot(epochs, gan.history['g_loss'], label='Generator Loss', linewidth=2, color='red')\n",
    "    axes[0, 0].plot(epochs, gan.history['d_loss'], label='Discriminator Loss', linewidth=2, color='blue')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('Training Loss Curves')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy curves\n",
    "    axes[0, 1].plot(epochs, gan.history['real_acc'], label='Real Data Accuracy', linewidth=2, color='green')\n",
    "    axes[0, 1].plot(epochs, gan.history['fake_acc'], label='Fake Data Accuracy', linewidth=2, color='orange')\n",
    "    axes[0, 1].axhline(y=0.5, color='black', linestyle='--', alpha=0.7, label='Random Guess')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].set_title('Discriminator Accuracy')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].set_ylim(0, 1)\n",
    "    \n",
    "    # Final comparison\n",
    "    real_data = real_dataset.data.numpy()\n",
    "    generated_data = gan.generate_samples(2000)\n",
    "    \n",
    "    axes[1, 0].scatter(real_data[:, 0], real_data[:, 1], alpha=0.5, s=8, \n",
    "                      color='blue', label=f'Real Data ({len(real_data)} samples)')\n",
    "    axes[1, 0].scatter(generated_data[:, 0], generated_data[:, 1], alpha=0.5, s=8, \n",
    "                      color='red', label=f'Generated Data ({len(generated_data)} samples)')\n",
    "    axes[1, 0].set_title('Final: Real vs Generated Data')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].axis('equal')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Training stability analysis\n",
    "    window_size = 10\n",
    "    if len(gan.history['g_loss']) >= window_size:\n",
    "        g_loss_smooth = np.convolve(gan.history['g_loss'], np.ones(window_size)/window_size, mode='valid')\n",
    "        d_loss_smooth = np.convolve(gan.history['d_loss'], np.ones(window_size)/window_size, mode='valid')\n",
    "        smooth_epochs = epochs[window_size-1:]\n",
    "        \n",
    "        axes[1, 1].plot(smooth_epochs, g_loss_smooth, label='Generator (Smoothed)', linewidth=2, alpha=0.8)\n",
    "        axes[1, 1].plot(smooth_epochs, d_loss_smooth, label='Discriminator (Smoothed)', linewidth=2, alpha=0.8)\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Smoothed Loss')\n",
    "        axes[1, 1].set_title('Training Stability (Moving Average)')\n",
    "        axes[1, 1].legend()\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(notebook_results_dir / 'analysis' / 'vanilla_gan_training_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Quantitative evaluation\n",
    "    print(f\"\\nüéØ Final Training Metrics:\")\n",
    "    print(f\"   Final Generator Loss: {gan.history['g_loss'][-1]:.4f}\")\n",
    "    print(f\"   Final Discriminator Loss: {gan.history['d_loss'][-1]:.4f}\")\n",
    "    print(f\"   Real Data Accuracy: {gan.history['real_acc'][-1]:.3f}\")\n",
    "    print(f\"   Fake Data Accuracy: {gan.history['fake_acc'][-1]:.3f}\")\n",
    "    print(f\"   Training Balance: {abs(gan.history['real_acc'][-1] - 0.5) + abs(gan.history['fake_acc'][-1] - 0.5):.3f} (lower is better)\")\n",
    "\n",
    "analyze_vanilla_gan_training(vanilla_gan, gaussian_dataset)\n",
    "\n",
    "print(\"‚úÖ Vanilla GAN training and analysis completed!\")\n",
    "```\n",
    "\n",
    "## 4. Deep Convolutional GAN (DCGAN) Implementation\n",
    "\n",
    "Advanced GAN architecture for high-quality image generation with convolutional layers.\n",
    "\n",
    "```python\n",
    "def weights_init_dcgan(module):\n",
    "    \"\"\"Initialize weights according to DCGAN paper recommendations.\"\"\"\n",
    "    classname = module.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(module.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(module.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(module.bias.data, 0)\n",
    "\n",
    "class DCGANGenerator(nn.Module):\n",
    "    \"\"\"DCGAN Generator for high-quality image generation.\"\"\"\n",
    "    \n",
    "    def __init__(self, nz=100, ngf=64, nc=3, img_size=64):\n",
    "        super(DCGANGenerator, self).__init__()\n",
    "        \n",
    "        self.nz = nz\n",
    "        self.ngf = ngf\n",
    "        self.nc = nc\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # Input: Z latent vector (nz x 1 x 1)\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # State: (ngf*8) x 4 x 4\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # State: (ngf*4) x 8 x 8\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # State: (ngf*2) x 16 x 16\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # State: (ngf) x 32 x 32\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # Output: (nc) x 64 x 64\n",
    "        )\n",
    "        \n",
    "        self.apply(weights_init_dcgan)\n",
    "        self.total_params = sum(p.numel() for p in self.parameters())\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "class DCGANDiscriminator(nn.Module):\n",
    "    \"\"\"DCGAN Discriminator for image classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, nc=3, ndf=64, img_size=64):\n",
    "        super(DCGANDiscriminator, self).__init__()\n",
    "        \n",
    "        self.nc = nc\n",
    "        self.ndf = ndf\n",
    "        self.img_size = img_size\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # Input: (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State: (ndf) x 32 x 32\n",
    "            \n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State: (ndf*2) x 16 x 16\n",
    "            \n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State: (ndf*4) x 8 x 8\n",
    "            \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # State: (ndf*8) x 4 x 4\n",
    "            \n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "            # Output: 1 x 1 x 1\n",
    "        )\n",
    "        \n",
    "        self.apply(weights_init_dcgan)\n",
    "        self.total_params = sum(p.numel() for p in self.parameters())\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1).squeeze(1)\n",
    "\n",
    "class SyntheticImageDataset(Dataset):\n",
    "    \"\"\"Generate synthetic colored geometric patterns for DCGAN training.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_samples=10000, img_size=64, num_channels=3):\n",
    "        self.num_samples = num_samples\n",
    "        self.img_size = img_size\n",
    "        self.num_channels = num_channels\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        \n",
    "        print(f\"üé® Synthetic Image Dataset Created:\")\n",
    "        print(f\"   Samples: {num_samples}\")\n",
    "        print(f\"   Image size: {img_size}x{img_size}\")\n",
    "        print(f\"   Channels: {num_channels}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Generate a single synthetic image.\"\"\"\n",
    "        np.random.seed(idx)\n",
    "        \n",
    "        img = torch.zeros(self.num_channels, self.img_size, self.img_size)\n",
    "        \n",
    "        pattern_type = np.random.choice(['circles', 'squares', 'stripes', 'gradients'])\n",
    "        \n",
    "        if pattern_type == 'circles':\n",
    "            num_circles = np.random.randint(1, 4)\n",
    "            for _ in range(num_circles):\n",
    "                center_x = np.random.randint(self.img_size//4, 3*self.img_size//4)\n",
    "                center_y = np.random.randint(self.img_size//4, 3*self.img_size//4)\n",
    "                radius = np.random.randint(8, self.img_size//4)\n",
    "                \n",
    "                y, x = torch.meshgrid(torch.arange(self.img_size), torch.arange(self.img_size), indexing='ij')\n",
    "                mask = (x - center_x)**2 + (y - center_y)**2 <= radius**2\n",
    "                \n",
    "                color = torch.rand(3)\n",
    "                for c in range(3):\n",
    "                    img[c][mask] = color[c]\n",
    "                    \n",
    "        elif pattern_type == 'squares':\n",
    "            num_squares = np.random.randint(1, 3)\n",
    "            for _ in range(num_squares):\n",
    "                x1 = np.random.randint(0, self.img_size//2)\n",
    "                y1 = np.random.randint(0, self.img_size//2)\n",
    "                width = np.random.randint(12, self.img_size//2)\n",
    "                height = np.random.randint(12, self.img_size//2)\n",
    "                x2 = min(x1 + width, self.img_size)\n",
    "                y2 = min(y1 + height, self.img_size)\n",
    "                \n",
    "                color = torch.rand(3)\n",
    "                for c in range(3):\n",
    "                    img[c, y1:y2, x1:x2] = color[c]\n",
    "                    \n",
    "        elif pattern_type == 'stripes':\n",
    "            stripe_width = np.random.randint(4, 12)\n",
    "            direction = np.random.choice(['horizontal', 'vertical'])\n",
    "            \n",
    "            color1 = torch.rand(3)\n",
    "            color2 = torch.rand(3)\n",
    "            \n",
    "            if direction == 'horizontal':\n",
    "                for i in range(0, self.img_size, stripe_width * 2):\n",
    "                    for c in range(3):\n",
    "                        img[c, i:min(i+stripe_width, self.img_size), :] = color1[c]\n",
    "                        if i + stripe_width < self.img_size:\n",
    "                            img[c, i+stripe_width:min(i+2*stripe_width, self.img_size), :] = color2[c]\n",
    "            else:\n",
    "                for i in range(0, self.img_size, stripe_width * 2):\n",
    "                    for c in range(3):\n",
    "                        img[c, :, i:min(i+stripe_width, self.img_size)] = color1[c]\n",
    "                        if i + stripe_width < self.img_size:\n",
    "                            img[c, :, i+stripe_width:min(i+2*stripe_width, self.img_size)] = color2[c]\n",
    "                            \n",
    "        else:  # gradients\n",
    "            direction = np.random.choice(['horizontal', 'vertical', 'radial'])\n",
    "            color1 = torch.rand(3)\n",
    "            color2 = torch.rand(3)\n",
    "            \n",
    "            if direction == 'horizontal':\n",
    "                for j in range(self.img_size):\n",
    "                    alpha = j / (self.img_size - 1)\n",
    "                    blended_color = (1 - alpha) * color1 + alpha * color2\n",
    "                    for c in range(3):\n",
    "                        img[c, :, j] = blended_color[c]\n",
    "            elif direction == 'vertical':\n",
    "                for i in range(self.img_size):\n",
    "                    alpha = i / (self.img_size - 1)\n",
    "                    blended_color = (1 - alpha) * color1 + alpha * color2\n",
    "                    for c in range(3):\n",
    "                        img[c, i, :] = blended_color[c]\n",
    "            else:  # radial\n",
    "                center_x, center_y = self.img_size // 2, self.img_size // 2\n",
    "                max_distance = np.sqrt(2) * self.img_size / 2\n",
    "                for i in range(self.img_size):\n",
    "                    for j in range(self.img_size):\n",
    "                        distance = np.sqrt((i - center_y)**2 + (j - center_x)**2)\n",
    "                        alpha = min(distance / max_distance, 1.0)\n",
    "                        blended_color = (1 - alpha) * color1 + alpha * color2\n",
    "                        for c in range(3):\n",
    "                            img[c, i, j] = blended_color[c]\n",
    "        \n",
    "        # Add noise and normalize\n",
    "        noise_level = 0.05\n",
    "        img += noise_level * torch.randn_like(img)\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        img = self.transform(img)\n",
    "        \n",
    "        return img\n",
    "\n",
    "class DCGAN:\n",
    "    \"\"\"Complete DCGAN implementation with comprehensive training and evaluation.\"\"\"\n",
    "    \n",
    "    def __init__(self, nz=100, lr=0.0002, beta1=0.5, ngf=64, ndf=64):\n",
    "        self.nz = nz\n",
    "        self.lr = lr\n",
    "        self.beta1 = beta1\n",
    "        \n",
    "        # Initialize networks\n",
    "        self.netG = DCGANGenerator(nz=nz, ngf=ngf).to(device)\n",
    "        self.netD = DCGANDiscriminator(ndf=ndf).to(device)\n",
    "        \n",
    "        print(f\"üèóÔ∏è DCGAN Architecture:\")\n",
    "        print(f\"   Generator parameters: {self.netG.total_params:,}\")\n",
    "        print(f\"   Discriminator parameters: {self.netD.total_params:,}\")\n",
    "        print(f\"   Total parameters: {self.netG.total_params + self.netD.total_params:,}\")\n",
    "        \n",
    "        # Optimizers\n",
    "        self.optimizerG = optim.Adam(self.netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "        self.optimizerD = optim.Adam(self.netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "        \n",
    "        # Loss function\n",
    "        self.criterion = nn.BCELoss()\n",
    "        \n",
    "        # Fixed noise for evaluation\n",
    "        self.fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "        \n",
    "        # Training history\n",
    "        self.history = {\n",
    "            'g_loss': [], 'd_loss': [], 'd_real': [], 'd_fake': [],\n",
    "            'epochs': []\n",
    "        }\n",
    "    \n",
    "    def train_step(self, real_batch):\n",
    "        \"\"\"Single training step for DCGAN.\"\"\"\n",
    "        batch_size = real_batch.size(0)\n",
    "        \n",
    "        real_label = 1.0\n",
    "        fake_label = 0.0\n",
    "        \n",
    "        # Update Discriminator\n",
    "        self.netD.zero_grad()\n",
    "        \n",
    "        # Train with real\n",
    "        real_batch = real_batch.to(device)\n",
    "        label = torch.full((batch_size,), real_label, dtype=torch.float, device=device)\n",
    "        \n",
    "        output = self.netD(real_batch).view(-1)\n",
    "        errD_real = self.criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "        \n",
    "        # Train with fake\n",
    "        noise = torch.randn(batch_size, self.nz, 1, 1, device=device)\n",
    "        fake = self.netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        \n",
    "        output = self.netD(fake.detach()).view(-1)\n",
    "        errD_fake = self.criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        \n",
    "        errD = errD_real + errD_fake\n",
    "        self.optimizerD.step()\n",
    "        \n",
    "        # Update Generator\n",
    "        self.netG.zero_grad()\n",
    "        label.fill_(real_label)\n",
    "        \n",
    "        output = self.netD(fake).view(-1)\n",
    "        errG = self.criterion(output, label)\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        \n",
    "        self.optimizerG.step()\n",
    "        \n",
    "        return errG.item(), errD.item(), D_x, D_G_z1, D_G_z2\n",
    "    \n",
    "    def train(self, dataloader, num_epochs, save_interval=10, eval_interval=5):\n",
    "        \"\"\"Complete DCGAN training loop.\"\"\"\n",
    "        print(f\"üöÄ Training DCGAN for {num_epochs} epochs...\")\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_g_loss = 0\n",
    "            epoch_d_loss = 0\n",
    "            epoch_d_real = 0\n",
    "            epoch_d_fake = 0\n",
    "            num_batches = 0\n",
    "            \n",
    "            progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            \n",
    "            for i, data in enumerate(progress_bar):\n",
    "                g_loss, d_loss, d_real, d_fake1, d_fake2 = self.train_step(data)\n",
    "                \n",
    "                epoch_g_loss += g_loss\n",
    "                epoch_d_loss += d_loss\n",
    "                epoch_d_real += d_real\n",
    "                epoch_d_fake += d_fake1\n",
    "                num_batches += 1\n",
    "                \n",
    "                progress_bar.set_postfix({\n",
    "                    'G_Loss': f'{g_loss:.3f}',\n",
    "                    'D_Loss': f'{d_loss:.3f}',\n",
    "                    'D(x)': f'{d_real:.3f}',\n",
    "                    'D(G(z))': f'{d_fake1:.3f}'\n",
    "                })\n",
    "            \n",
    "            # Calculate averages\n",
    "            avg_g_loss = epoch_g_loss / num_batches\n",
    "            avg_d_loss = epoch_d_loss / num_batches\n",
    "            avg_d_real = epoch_d_real / num_batches\n",
    "            avg_d_fake = epoch_d_fake / num_batches\n",
    "            \n",
    "            # Store history\n",
    "            self.history['g_loss'].append(avg_g_loss)\n",
    "            self.history['d_loss'].append(avg_d_loss)\n",
    "            self.history['d_real'].append(avg_d_real)\n",
    "            self.history['d_fake'].append(avg_d_fake)\n",
    "            self.history['epochs'].append(epoch + 1)\n",
    "            \n",
    "            if (epoch + 1) % save_interval == 0:\n",
    "                print(f\"[{epoch+1:3d}/{num_epochs}] \"\n",
    "                      f\"G_Loss: {avg_g_loss:.4f} D_Loss: {avg_d_loss:.4f} \"\n",
    "                      f\"D(x): {avg_d_real:.4f} D(G(z)): {avg_d_fake:.4f}\")\n",
    "            \n",
    "            if (epoch + 1) % eval_interval == 0:\n",
    "                self.generate_and_save_images(epoch + 1)\n",
    "    \n",
    "    def generate_and_save_images(self, epoch, num_images=64):\n",
    "        \"\"\"Generate and save images for evaluation.\"\"\"\n",
    "        self.netG.eval()\n",
    "        with torch.no_grad():\n",
    "            fake = self.netG(self.fixed_noise[:num_images])\n",
    "            \n",
    "            grid = vutils.make_grid(fake, padding=2, normalize=True, nrow=8)\n",
    "            \n",
    "            plt.figure(figsize=(12, 12))\n",
    "            plt.imshow(np.transpose(grid.cpu().numpy(), (1, 2, 0)))\n",
    "            plt.title(f'DCGAN Generated Images - Epoch {epoch}')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            save_path = notebook_results_dir / 'generated_images' / f'dcgan_epoch_{epoch}.png'\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "        \n",
    "        self.netG.train()\n",
    "    \n",
    "    def generate_samples(self, num_samples=64):\n",
    "        \"\"\"Generate random samples from trained generator.\"\"\"\n",
    "        self.netG.eval()\n",
    "        with torch.no_grad():\n",
    "            noise = torch.randn(num_samples, self.nz, 1, 1, device=device)\n",
    "            samples = self.netG(noise)\n",
    "        self.netG.train()\n",
    "        return samples\n",
    "\n",
    "# Create and train DCGAN\n",
    "print(\"\\nüé® Training DCGAN on Synthetic Images:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create synthetic image dataset\n",
    "img_dataset = SyntheticImageDataset(num_samples=8000, img_size=64)\n",
    "img_dataloader = DataLoader(img_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "\n",
    "# Show sample real images\n",
    "print(\"üì∑ Sample Real Images from Dataset:\")\n",
    "sample_batch = next(iter(img_dataloader))\n",
    "plt.figure(figsize=(12, 8))\n",
    "grid = vutils.make_grid(sample_batch[:32], padding=2, normalize=True, nrow=8)\n",
    "plt.imshow(np.transpose(grid.numpy(), (1, 2, 0)))\n",
    "plt.title('Sample Real Images from Synthetic Dataset')\n",
    "plt.axis('off')\n",
    "plt.savefig(notebook_results_dir / 'analysis' / 'sample_real_images.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Initialize and train DCGAN\n",
    "dcgan = DCGAN(nz=100, lr=0.0002, beta1=0.5)\n",
    "dcgan.train(img_dataloader, num_epochs=50, save_interval=10, eval_interval=10)\n",
    "\n",
    "print(\"‚úÖ DCGAN training completed!\")\n",
    "```\n",
    "\n",
    "## 5. Wasserstein GAN with Gradient Penalty (WGAN-GP)\n",
    "\n",
    "Advanced GAN variant addressing training stability issues through Wasserstein distance and gradient penalty.\n",
    "\n",
    "```python\n",
    "class WGANGenerator(nn.Module):\n",
    "    \"\"\"Wasserstein GAN Generator with architecture similar to DCGAN.\"\"\"\n",
    "    \n",
    "    def __init__(self, nz=100, ngf=64, nc=3):\n",
    "        super(WGANGenerator, self).__init__()\n",
    "        \n",
    "        self.nz = nz\n",
    "        self.ngf = ngf\n",
    "        self.nc = nc\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d(nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        self.apply(weights_init_dcgan)\n",
    "        self.total_params = sum(p.numel() for p in self.parameters())\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "class WGANCritic(nn.Module):\n",
    "    \"\"\"Wasserstein GAN Critic (Discriminator without final sigmoid).\"\"\"\n",
    "    \n",
    "    def __init__(self, nc=3, ndf=64):\n",
    "        super(WGANCritic, self).__init__()\n",
    "        \n",
    "        self.nc = nc\n",
    "        self.ndf = ndf\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.InstanceNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False)\n",
    "        )\n",
    "        \n",
    "        self.apply(weights_init_dcgan)\n",
    "        self.total_params = sum(p.numel() for p in self.parameters())\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.main(input).view(-1, 1).squeeze(1)\n",
    "\n",
    "class WGAN_GP:\n",
    "    \"\"\"Wasserstein GAN with Gradient Penalty implementation.\"\"\"\n",
    "    \n",
    "    def __init__(self, nz=100, lr=0.0001, lambda_gp=10, n_critic=5):\n",
    "        self.nz = nz\n",
    "        self.lr = lr\n",
    "        self.lambda_gp = lambda_gp\n",
    "        self.n_critic = n_critic\n",
    "        \n",
    "        # Initialize networks\n",
    "        self.netG = WGANGenerator(nz=nz).to(device)\n",
    "        self.netC = WGANCritic().to(device)\n",
    "        \n",
    "        print(f\"üåä WGAN-GP Architecture:\")\n",
    "        print(f\"   Generator parameters: {self.netG.total_params:,}\")\n",
    "        print(f\"   Critic parameters: {self.netC.total_params:,}\")\n",
    "        print(f\"   Total parameters: {self.netG.total_params + self.netC.total_params:,}\")\n",
    "        print(f\"   Lambda GP: {lambda_gp}\")\n",
    "        print(f\"   Critic updates per G update: {n_critic}\")\n",
    "        \n",
    "        # Optimizers\n",
    "        self.optimizerG = optim.Adam(self.netG.parameters(), lr=lr, betas=(0.0, 0.9))\n",
    "        self.optimizerC = optim.Adam(self.netC.parameters(), lr=lr, betas=(0.0, 0.9))\n",
    "        \n",
    "        # Fixed noise for evaluation\n",
    "        self.fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "        \n",
    "        # Training history\n",
    "        self.history = {\n",
    "            'g_loss': [], 'c_loss': [], 'wasserstein_distance': [], \n",
    "            'gradient_penalty': [], 'epochs': []\n",
    "        }\n",
    "    \n",
    "    def gradient_penalty(self, real_data, fake_data):\n",
    "        \"\"\"Calculate gradient penalty for WGAN-GP.\"\"\"\n",
    "        batch_size = real_data.size(0)\n",
    "        \n",
    "        alpha = torch.rand(batch_size, 1, 1, 1).to(device)\n",
    "        interpolates = alpha * real_data + (1 - alpha) * fake_data\n",
    "        interpolates = interpolates.to(device)\n",
    "        interpolates.requires_grad_(True)\n",
    "        \n",
    "        critic_interpolates = self.netC(interpolates)\n",
    "        \n",
    "        gradients = torch.autograd.grad(\n",
    "            outputs=critic_interpolates,\n",
    "            inputs=interpolates,\n",
    "            grad_outputs=torch.ones(critic_interpolates.size()).to(device),\n",
    "            create_graph=True,\n",
    "            retain_graph=True,\n",
    "            only_inputs=True\n",
    "        )[0]\n",
    "        \n",
    "        gradients = gradients.view(gradients.size(0), -1)\n",
    "        gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "        \n",
    "        return gradient_penalty\n",
    "    \n",
    "    def train_step(self, real_batch):\n",
    "        \"\"\"Single training step for WGAN-GP.\"\"\"\n",
    "        batch_size = real_batch.size(0)\n",
    "        \n",
    "        noise = torch.randn(batch_size, self.nz, 1, 1, device=device)\n",
    "        fake_data = self.netG(noise)\n",
    "        \n",
    "        # Update Critic multiple times\n",
    "        critic_losses = []\n",
    "        gradient_penalties = []\n",
    "        \n",
    "        for _ in range(self.n_critic):\n",
    "            self.netC.zero_grad()\n",
    "            \n",
    "            critic_real = self.netC(real_batch).view(-1)\n",
    "            critic_fake = self.netC(fake_data.detach()).view(-1)\n",
    "            \n",
    "            gp = self.gradient_penalty(real_batch, fake_data.detach())\n",
    "            \n",
    "            critic_loss = -(torch.mean(critic_real) - torch.mean(critic_fake)) + self.lambda_gp * gp\n",
    "            \n",
    "            critic_loss.backward()\n",
    "            self.optimizerC.step()\n",
    "            \n",
    "            critic_losses.append(critic_loss.item())\n",
    "            gradient_penalties.append(gp.item())\n",
    "        \n",
    "        # Update Generator\n",
    "        self.netG.zero_grad()\n",
    "        \n",
    "        fake_data = self.netG(noise)\n",
    "        critic_fake = self.netC(fake_data).view(-1)\n",
    "        \n",
    "        gen_loss = -torch.mean(critic_fake)\n",
    "        \n",
    "        gen_loss.backward()\n",
    "        self.optimizerG.step()\n",
    "        \n",
    "        # Calculate Wasserstein distance estimate\n",
    "        with torch.no_grad():\n",
    "            critic_real = self.netC(real_batch).view(-1)\n",
    "            critic_fake = self.netC(fake_data).view(-1)\n",
    "            wasserstein_distance = torch.mean(critic_real) - torch.mean(critic_fake)\n",
    "        \n",
    "        return (gen_loss.item(), np.mean(critic_losses), \n",
    "                wasserstein_distance.item(), np.mean(gradient_penalties))\n",
    "    \n",
    "    def train(self, dataloader, num_epochs, save_interval=10, eval_interval=5):\n",
    "        \"\"\"Complete WGAN-GP training loop.\"\"\"\n",
    "        print(f\"üöÄ Training WGAN-GP for {num_epochs} epochs...\")\n",
    "        \n",
    "        for epoch in range(num_epochs):\n",
    "            epoch_g_loss = 0\n",
    "            epoch_c_loss = 0\n",
    "            epoch_wd = 0\n",
    "            epoch_gp = 0\n",
    "            num_batches = 0\n",
    "            \n",
    "            progress_bar = tqdm(dataloader, desc=f\"WGAN-GP Epoch {epoch+1}/{num_epochs}\")\n",
    "            \n",
    "            for i, data in enumerate(progress_bar):\n",
    "                real_batch = data.to(device)\n",
    "                \n",
    "                g_loss, c_loss, wd, gp = self.train_step(real_batch)\n",
    "                \n",
    "                epoch_g_loss += g_loss\n",
    "                epoch_c_loss += c_loss\n",
    "                epoch_wd += wd\n",
    "                epoch_gp += gp\n",
    "                num_batches += 1\n",
    "                \n",
    "                progress_bar.set_postfix({\n",
    "                    'G_Loss': f'{g_loss:.3f}',\n",
    "                    'C_Loss': f'{c_loss:.3f}',\n",
    "                    'W_Dist': f'{wd:.3f}',\n",
    "                    'GP': f'{gp:.3f}'\n",
    "                })\n",
    "            \n",
    "            # Calculate averages\n",
    "            avg_g_loss = epoch_g_loss / num_batches\n",
    "            avg_c_loss = epoch_c_loss / num_batches\n",
    "            avg_wd = epoch_wd / num_batches\n",
    "            avg_gp = epoch_gp / num_batches\n",
    "            \n",
    "            # Store history\n",
    "            self.history['g_loss'].append(avg_g_loss)\n",
    "            self.history['c_loss'].append(avg_c_loss)\n",
    "            self.history['wasserstein_distance'].append(avg_wd)\n",
    "            self.history['gradient_penalty'].append(avg_gp)\n",
    "            self.history['epochs'].append(epoch + 1)\n",
    "            \n",
    "            if (epoch + 1) % save_interval == 0:\n",
    "                print(f\"[{epoch+1:3d}/{num_epochs}] \"\n",
    "                      f\"G_Loss: {avg_g_loss:.4f} C_Loss: {avg_c_loss:.4f} \"\n",
    "                      f\"W_Dist: {avg_wd:.4f} GP: {avg_gp:.4f}\")\n",
    "            \n",
    "            if (epoch + 1) % eval_interval == 0:\n",
    "                self.generate_and_save_images(epoch + 1)\n",
    "    \n",
    "    def generate_and_save_images(self, epoch, num_images=64):\n",
    "        \"\"\"Generate and save images for evaluation.\"\"\"\n",
    "        self.netG.eval()\n",
    "        with torch.no_grad():\n",
    "            fake = self.netG(self.fixed_noise[:num_images])\n",
    "            \n",
    "            grid = vutils.make_grid(fake, padding=2, normalize=True, nrow=8)\n",
    "            \n",
    "            plt.figure(figsize=(12, 12))\n",
    "            plt.imshow(np.transpose(grid.cpu().numpy(), (1, 2, 0)))\n",
    "            plt.title(f'WGAN-GP Generated Images - Epoch {epoch}')\n",
    "            plt.axis('off')\n",
    "            \n",
    "            save_path = notebook_results_dir / 'generated_images' / f'wgan_gp_epoch_{epoch}.png'\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "        \n",
    "        self.netG.train()\n",
    "    \n",
    "    def generate_samples(self, num_samples=64):\n",
    "        \"\"\"Generate random samples from trained generator.\"\"\"\n",
    "        self.netG.eval()\n",
    "        with torch.no_grad():\n",
    "            noise = torch.randn(num_samples, self.nz, 1, 1, device=device)\n",
    "            samples = self.netG(noise)\n",
    "        self.netG.train()\n",
    "        return samples\n",
    "\n",
    "# Train WGAN-GP\n",
    "print(\"\\nüåä Training WGAN-GP:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "wgan_gp = WGAN_GP(nz=100, lr=0.0001, lambda_gp=10)\n",
    "wgan_gp.train(img_dataloader, num_epochs=40, save_interval=10, eval_interval=10)\n",
    "\n",
    "print(\"‚úÖ WGAN-GP training completed!\")\n",
    "```\n",
    "\n",
    "## 6. Comprehensive Training Dynamics Analysis\n",
    "\n",
    "Detailed comparison and analysis of different GAN variants and their training characteristics.\n",
    "\n",
    "```python\n",
    "def comprehensive_training_analysis():\n",
    "    \"\"\"Perform comprehensive analysis of all trained GANs.\"\"\"\n",
    "    print(\"üìä COMPREHENSIVE TRAINING DYNAMICS ANALYSIS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Create comprehensive comparison visualization\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
    "    \n",
    "    # 1. Loss Comparison\n",
    "    axes[0, 0].plot(dcgan.history['epochs'], dcgan.history['g_loss'], \n",
    "                   label='DCGAN Generator', linewidth=2, alpha=0.8)\n",
    "    axes[0, 0].plot(wgan_gp.history['epochs'], wgan_gp.history['g_loss'], \n",
    "                   label='WGAN-GP Generator', linewidth=2, alpha=0.8)\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Generator Loss')\n",
    "    axes[0, 0].set_title('Generator Loss Comparison')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[0, 1].plot(dcgan.history['epochs'], dcgan.history['d_loss'], \n",
    "                   label='DCGAN Discriminator', linewidth=2, alpha=0.8)\n",
    "    axes[0, 1].plot(wgan_gp.history['epochs'], wgan_gp.history['c_loss'], \n",
    "                   label='WGAN-GP Critic', linewidth=2, alpha=0.8)\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Discriminator/Critic Loss')\n",
    "    axes[0, 1].set_title('Discriminator/Critic Loss Comparison')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. DCGAN Discriminator Performance\n",
    "    axes[0, 2].plot(dcgan.history['epochs'], dcgan.history['d_real'], \n",
    "                   label='D(real)', linewidth=2, alpha=0.8, color='blue')\n",
    "    axes[0, 2].plot(dcgan.history['epochs'], dcgan.history['d_fake'], \n",
    "                   label='D(fake)', linewidth=2, alpha=0.8, color='red')\n",
    "    axes[0, 2].axhline(y=0.5, color='black', linestyle='--', alpha=0.7, label='Optimal (0.5)')\n",
    "    axes[0, 2].set_xlabel('Epoch')\n",
    "    axes[0, 2].set_ylabel('Discriminator Output')\n",
    "    axes[0, 2].set_title('DCGAN Discriminator Performance')\n",
    "    axes[0, 2].legend()\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    axes[0, 2].set_ylim(0, 1)\n",
    "    \n",
    "    # 3. WGAN-GP Specific Metrics\n",
    "    axes[0, 3].plot(wgan_gp.history['epochs'], wgan_gp.history['wasserstein_distance'], \n",
    "                   label='Wasserstein Distance', linewidth=2, alpha=0.8, color='green')\n",
    "    axes[0, 3].plot(wgan_gp.history['epochs'], wgan_gp.history['gradient_penalty'], \n",
    "                   label='Gradient Penalty', linewidth=2, alpha=0.8, color='purple')\n",
    "    axes[0, 3].set_xlabel('Epoch')\n",
    "    axes[0, 3].set_ylabel('Value')\n",
    "    axes[0, 3].set_title('WGAN-GP Specific Metrics')\n",
    "    axes[0, 3].legend()\n",
    "    axes[0, 3].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Generated Images Comparison\n",
    "    axes[1, 0].set_title('DCGAN Generated Images')\n",
    "    dcgan_samples = dcgan.netG(dcgan.fixed_noise[:16])\n",
    "    grid = vutils.make_grid(dcgan_samples, padding=2, normalize=True, nrow=4)\n",
    "    axes[1, 0].imshow(np.transpose(grid.cpu().detach().numpy(), (1, 2, 0)))\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    axes[1, 1].set_title('WGAN-GP Generated Images')\n",
    "    wgan_samples = wgan_gp.generate_samples(16)\n",
    "    grid = vutils.make_grid(wgan_samples, padding=2, normalize=True, nrow=4)\n",
    "    axes[1, 1].imshow(np.transpose(grid.cpu().detach().numpy(), (1, 2, 0)))\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    # 5. Training Stability Analysis\n",
    "    def calculate_stability(losses, window=5):\n",
    "        \"\"\"Calculate rolling standard deviation as stability metric.\"\"\"\n",
    "        if len(losses) < window:\n",
    "            return [0] * len(losses)\n",
    "        \n",
    "        stability = []\n",
    "        for i in range(len(losses)):\n",
    "            start_idx = max(0, i - window + 1)\n",
    "            window_losses = losses[start_idx:i+1]\n",
    "            stability.append(np.std(window_losses))\n",
    "        return stability\n",
    "    \n",
    "    dcgan_g_stability = calculate_stability(dcgan.history['g_loss'])\n",
    "    wgan_g_stability = calculate_stability(wgan_gp.history['g_loss'])\n",
    "    \n",
    "    axes[1, 2].plot(dcgan.history['epochs'], dcgan_g_stability, \n",
    "                   label='DCGAN Stability', linewidth=2, alpha=0.8)\n",
    "    axes[1, 2].plot(wgan_gp.history['epochs'], wgan_g_stability, \n",
    "                   label='WGAN-GP Stability', linewidth=2, alpha=0.8)\n",
    "    axes[1, 2].set_xlabel('Epoch')\n",
    "    axes[1, 2].set_ylabel('Loss Std Dev (5-epoch window)')\n",
    "    axes[1, 2].set_title('Training Stability Comparison')\n",
    "    axes[1, 2].legend()\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Convergence Analysis\n",
    "    def calculate_convergence_rate(losses):\n",
    "        \"\"\"Calculate how quickly losses converge.\"\"\"\n",
    "        if len(losses) < 10:\n",
    "            return 0\n",
    "        \n",
    "        cutoff = int(len(losses) * 0.75)\n",
    "        initial_avg = np.mean(losses[:5])\n",
    "        final_avg = np.mean(losses[cutoff-5:cutoff])\n",
    "        \n",
    "        convergence_rate = (initial_avg - final_avg) / initial_avg if initial_avg != 0 else 0\n",
    "        return max(0, convergence_rate)\n",
    "    \n",
    "    dcgan_conv_rate = calculate_convergence_rate(dcgan.history['g_loss'])\n",
    "    wgan_conv_rate = calculate_convergence_rate(wgan_gp.history['g_loss'])\n",
    "    \n",
    "    models = ['DCGAN', 'WGAN-GP']\n",
    "    conv_rates = [dcgan_conv_rate, wgan_conv_rate]\n",
    "    \n",
    "    bars = axes[1, 3].bar(models, conv_rates, alpha=0.8, color=['skyblue', 'lightgreen'])\n",
    "    axes[1, 3].set_ylabel('Convergence Rate')\n",
    "    axes[1, 3].set_title('Generator Convergence Rate')\n",
    "    axes[1, 3].set_ylim(0, max(conv_rates) * 1.2 if max(conv_rates) > 0 else 1)\n",
    "    \n",
    "    for bar, rate in zip(bars, conv_rates):\n",
    "        height = bar.get_height()\n",
    "        axes[1, 3].text(bar.get_x() + bar.get_width()/2., height + max(conv_rates)*0.01,\n",
    "                        f'{rate:.3f}', ha='center', va='bottom')\n",
    "    \n",
    "    axes[1, 3].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 7. Loss Correlation Analysis\n",
    "    if len(dcgan.history['g_loss']) >= 10:\n",
    "        dcgan_correlation = np.corrcoef(dcgan.history['g_loss'], dcgan.history['d_loss'])[0, 1]\n",
    "        wgan_correlation = np.corrcoef(wgan_gp.history['g_loss'], wgan_gp.history['c_loss'])[0, 1]\n",
    "        \n",
    "        correlations = [dcgan_correlation, wgan_correlation]\n",
    "        bars = axes[2, 0].bar(models, correlations, alpha=0.8, color=['orange', 'purple'])\n",
    "        axes[2, 0].set_ylabel('Loss Correlation')\n",
    "        axes[2, 0].set_title('Generator-Discriminator Loss Correlation')\n",
    "        axes[2, 0].axhline(y=0, color='black', linestyle='-', alpha=0.5)\n",
    "        \n",
    "        for bar, corr in zip(bars, correlations):\n",
    "            height = bar.get_height()\n",
    "            axes[2, 0].text(bar.get_x() + bar.get_width()/2., \n",
    "                           height + 0.02 if height >= 0 else height - 0.05,\n",
    "                           f'{corr:.3f}', ha='center', va='bottom' if height >= 0 else 'top')\n",
    "        \n",
    "        axes[2, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 8. Final Performance Metrics\n",
    "    final_metrics = {\n",
    "        'DCGAN': {\n",
    "            'G_Loss': dcgan.history['g_loss'][-1],\n",
    "            'D_Loss': dcgan.history['d_loss'][-1],\n",
    "            'D(real)': dcgan.history['d_real'][-1],\n",
    "            'D(fake)': dcgan.history['d_fake'][-1],\n",
    "            'Balance': abs(dcgan.history['d_real'][-1] - dcgan.history['d_fake'][-1])\n",
    "        },\n",
    "        'WGAN-GP': {\n",
    "            'G_Loss': wgan_gp.history['g_loss'][-1],\n",
    "            'C_Loss': wgan_gp.history['c_loss'][-1],\n",
    "            'W_Distance': wgan_gp.history['wasserstein_distance'][-1],\n",
    "            'Grad_Penalty': wgan_gp.history['gradient_penalty'][-1]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create text summary\n",
    "    summary_text = \"FINAL METRICS SUMMARY\\n\\n\"\n",
    "    for model, metrics in final_metrics.items():\n",
    "        summary_text += f\"{model}:\\n\"\n",
    "        for metric, value in metrics.items():\n",
    "            summary_text += f\"  {metric}: {value:.4f}\\n\"\n",
    "        summary_text += \"\\n\"\n",
    "    \n",
    "    axes[2, 1].text(0.05, 0.95, summary_text, transform=axes[2, 1].transAxes, \n",
    "                   fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
    "    axes[2, 1].set_title('Final Performance Summary')\n",
    "    axes[2, 1].axis('off')\n",
    "    \n",
    "    # 9. Model Complexity Comparison\n",
    "    table_text = \"MODEL COMPARISON\\n\\n\"\n",
    "    table_text += f\"{'Metric':<18} {'DCGAN':<12} {'WGAN-GP':<12}\\n\"\n",
    "    table_text += \"-\" * 42 + \"\\n\"\n",
    "    table_text += f\"{'G Params':<18} {dcgan.netG.total_params:<12,} {wgan_gp.netG.total_params:<12,}\\n\"\n",
    "    table_text += f\"{'D/C Params':<18} {dcgan.netD.total_params:<12,} {wgan_gp.netC.total_params:<12,}\\n\"\n",
    "    table_text += f\"{'Final G Loss':<18} {dcgan.history['g_loss'][-1]:<12.4f} {wgan_gp.history['g_loss'][-1]:<12.4f}\\n\"\n",
    "    table_text += f\"{'Stability':<18} {'Moderate':<12} {'High':<12}\\n\"\n",
    "    \n",
    "    axes[2, 2].text(0.05, 0.95, table_text, transform=axes[2, 2].transAxes, \n",
    "                   fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "    axes[2, 2].set_title('Model Architecture Comparison')\n",
    "    axes[2, 2].axis('off')\n",
    "    \n",
    "    # 10. Training Recommendations\n",
    "    recommendations = []\n",
    "    \n",
    "    # Check DCGAN balance\n",
    "    dcgan_balance = final_metrics['DCGAN']['Balance']\n",
    "    if dcgan_balance > 0.2:\n",
    "        recommendations.append(\"DCGAN: Consider learning rate adjustment\")\n",
    "    \n",
    "    # Check WGAN-GP gradient penalty\n",
    "    wgan_gp_penalty = final_metrics['WGAN-GP']['Grad_Penalty']\n",
    "    if wgan_gp_penalty < 5 or wgan_gp_penalty > 15:\n",
    "        recommendations.append(\"WGAN-GP: Tune gradient penalty coefficient\")\n",
    "    \n",
    "    # Stability recommendations\n",
    "    if np.std(dcgan.history['g_loss'][-10:]) > np.std(wgan_gp.history['g_loss'][-10:]):\n",
    "        recommendations.append(\"DCGAN shows higher instability\")\n",
    "    \n",
    "    if not recommendations:\n",
    "        recommendations.append(\"Both models show good training characteristics\")\n",
    "    \n",
    "    rec_text = \"TRAINING RECOMMENDATIONS\\n\\n\"\n",
    "    for i, rec in enumerate(recommendations, 1):\n",
    "        rec_text += f\"{i}. {rec}\\n\"\n",
    "    \n",
    "    axes[2, 3].text(0.05, 0.95, rec_text, transform=axes[2, 3].transAxes, \n",
    "                   fontsize=10, verticalalignment='top', fontfamily='monospace',\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "    axes[2, 3].set_title('Training Recommendations')\n",
    "    axes[2, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(notebook_results_dir / 'analysis' / 'comprehensive_training_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return final_metrics\n",
    "\n",
    "# Perform comprehensive analysis\n",
    "print(\"\\nüî¨ Comprehensive Training Dynamics Analysis:\")\n",
    "training_analysis_results = comprehensive_training_analysis()\n",
    "\n",
    "def print_quantitative_analysis():\n",
    "    \"\"\"Print detailed quantitative analysis of training results.\"\"\"\n",
    "    print(\"\\nüìä QUANTITATIVE TRAINING ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # DCGAN Analysis\n",
    "    dcgan_final_metrics = training_analysis_results['DCGAN']\n",
    "    print(f\"\\nüé® DCGAN Results:\")\n",
    "    print(f\"   Final Generator Loss: {dcgan_final_metrics['G_Loss']:.4f}\")\n",
    "    print(f\"   Final Discriminator Loss: {dcgan_final_metrics['D_Loss']:.4f}\")\n",
    "    print(f\"   D(real) convergence: {dcgan_final_metrics['D(real)']:.4f} (target: ~0.5)\")\n",
    "    print(f\"   D(fake) convergence: {dcgan_final_metrics['D(fake)']:.4f} (target: ~0.5)\")\n",
    "    print(f\"   Training balance score: {dcgan_final_metrics['Balance']:.4f} (lower is better)\")\n",
    "    \n",
    "    # WGAN-GP Analysis\n",
    "    wgan_final_metrics = training_analysis_results['WGAN-GP']\n",
    "    print(f\"\\nüåä WGAN-GP Results:\")\n",
    "    print(f\"   Final Generator Loss: {wgan_final_metrics['G_Loss']:.4f}\")\n",
    "    print(f\"   Final Critic Loss: {wgan_final_metrics['C_Loss']:.4f}\")\n",
    "    print(f\"   Wasserstein Distance: {wgan_final_metrics['W_Distance']:.4f}\")\n",
    "    print(f\"   Gradient Penalty: {wgan_final_metrics['Grad_Penalty']:.4f}\")\n",
    "    \n",
    "    # Training Stability Comparison\n",
    "    dcgan_g_stability = np.std(dcgan.history['g_loss'][-10:])\n",
    "    wgan_g_stability = np.std(wgan_gp.history['g_loss'][-10:])\n",
    "    \n",
    "    print(f\"\\n‚öñÔ∏è Training Stability Comparison (last 10 epochs):\")\n",
    "    print(f\"   DCGAN Generator Loss Std: {dcgan_g_stability:.4f}\")\n",
    "    print(f\"   WGAN-GP Generator Loss Std: {wgan_g_stability:.4f}\")\n",
    "    \n",
    "    if wgan_g_stability < dcgan_g_stability:\n",
    "        stability_winner = \"WGAN-GP\"\n",
    "        stability_improvement = (dcgan_g_stability - wgan_g_stability) / dcgan_g_stability * 100\n",
    "    else:\n",
    "        stability_winner = \"DCGAN\"\n",
    "        stability_improvement = (wgan_g_stability - dcgan_g_stability) / wgan_g_stability * 100\n",
    "    \n",
    "    print(f\"   üèÜ Most stable: {stability_winner} ({stability_improvement:.1f}% better)\")\n",
    "    \n",
    "    # Performance Summary\n",
    "    print(f\"\\nüéØ Overall Assessment:\")\n",
    "    \n",
    "    # DCGAN assessment\n",
    "    dcgan_balance = dcgan_final_metrics['Balance']\n",
    "    if dcgan_balance < 0.1:\n",
    "        dcgan_status = \"‚úÖ Excellent balance\"\n",
    "    elif dcgan_balance < 0.2:\n",
    "        dcgan_status = \"‚ö†Ô∏è Good balance\"\n",
    "    else:\n",
    "        dcgan_status = \"‚ùå Poor balance\"\n",
    "    \n",
    "    print(f\"   DCGAN Status: {dcgan_status}\")\n",
    "    \n",
    "    # WGAN-GP assessment\n",
    "    wgan_gp_penalty = wgan_final_metrics['Grad_Penalty']\n",
    "    if 5 <= wgan_gp_penalty <= 15:\n",
    "        wgan_status = \"‚úÖ Optimal gradient penalty\"\n",
    "    elif 1 <= wgan_gp_penalty <= 25:\n",
    "        wgan_status = \"‚ö†Ô∏è Acceptable gradient penalty\"\n",
    "    else:\n",
    "        wgan_status = \"‚ùå Suboptimal gradient penalty\"\n",
    "    \n",
    "    print(f\"   WGAN-GP Status: {wgan_status}\")\n",
    "    \n",
    "    return {\n",
    "        'dcgan_stability': dcgan_g_stability,\n",
    "        'wgan_stability': wgan_g_stability,\n",
    "        'stability_winner': stability_winner,\n",
    "        'dcgan_status': dcgan_status,\n",
    "        'wgan_status': wgan_status\n",
    "    }\n",
    "\n",
    "# Print quantitative analysis\n",
    "quantitative_results = print_quantitative_analysis()\n",
    "\n",
    "print(\"‚úÖ Comprehensive training dynamics analysis completed!\")\n",
    "```\n",
    "\n",
    "## 7. Latent Space Exploration and Analysis\n",
    "\n",
    "Detailed exploration of the learned latent spaces and their properties across different GAN architectures.\n",
    "\n",
    "```python\n",
    "class LatentSpaceExplorer:\n",
    "    \"\"\"\n",
    "    Comprehensive latent space exploration and analysis toolkit.\n",
    "    \n",
    "    Provides tools for:\n",
    "    - Latent space interpolation\n",
    "    - Direction exploration\n",
    "    - Latent arithmetic operations\n",
    "    - Structure analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, generator, latent_dim, device):\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.device = device\n",
    "        \n",
    "    def interpolate_latent_space(self, z1, z2, num_steps=10):\n",
    "        \"\"\"Smoothly interpolate between two points in latent space.\"\"\"\n",
    "        self.generator.eval()\n",
    "        \n",
    "        interpolations = []\n",
    "        alphas = np.linspace(0, 1, num_steps)\n",
    "        \n",
    "        for alpha in alphas:\n",
    "            z_interp = (1 - alpha) * z1 + alpha * z2\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                sample = self.generator(z_interp)\n",
    "                interpolations.append(sample)\n",
    "        \n",
    "        self.generator.train()\n",
    "        return torch.cat(interpolations, dim=0)\n",
    "    \n",
    "    def explore_latent_directions(self, base_z, direction, steps=None):\n",
    "        \"\"\"Explore movement in a specific latent direction.\"\"\"\n",
    "        if steps is None:\n",
    "            steps = [-3, -2, -1, 0, 1, 2, 3]\n",
    "            \n",
    "        self.generator.eval()\n",
    "        \n",
    "        samples = []\n",
    "        for step in steps:\n",
    "            z_modified = base_z + step * direction\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                sample = self.generator(z_modified)\n",
    "                samples.append(sample)\n",
    "        \n",
    "        self.generator.train()\n",
    "        return torch.cat(samples, dim=0), steps\n",
    "    \n",
    "    def random_walk(self, start_z, num_steps=10, step_size=0.5):\n",
    "        \"\"\"Perform random walk in latent space.\"\"\"\n",
    "        self.generator.eval()\n",
    "        \n",
    "        current_z = start_z.clone()\n",
    "        walk_samples = []\n",
    "        \n",
    "        for _ in range(num_steps):\n",
    "            with torch.no_grad():\n",
    "                sample = self.generator(current_z)\n",
    "                walk_samples.append(sample)\n",
    "            \n",
    "            # Take random step\n",
    "            random_direction = torch.randn_like(current_z)\n",
    "            random_direction = random_direction / torch.norm(random_direction)\n",
    "            current_z = current_z + step_size * random_direction\n",
    "        \n",
    "        self.generator.train()\n",
    "        return torch.cat(walk_samples, dim=0)\n",
    "    \n",
    "    def analyze_latent_space_structure(self, num_samples=500):\n",
    "        \"\"\"Analyze the structure and properties of the latent space.\"\"\"\n",
    "        self.generator.eval()\n",
    "        \n",
    "        # Generate random latent codes\n",
    "        z_samples = torch.randn(num_samples, self.latent_dim, 1, 1, device=self.device)\n",
    "        \n",
    "        # Generate corresponding images\n",
    "        with torch.no_grad():\n",
    "            generated_images = self.generator(z_samples)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        z_flat = z_samples.view(num_samples, -1)\n",
    "        img_flat = generated_images.view(num_samples, -1)\n",
    "        \n",
    "        # Compute pairwise distances (sample subset for efficiency)\n",
    "        subset_size = min(100, num_samples)\n",
    "        indices = torch.randperm(num_samples)[:subset_size]\n",
    "        \n",
    "        z_subset = z_flat[indices]\n",
    "        img_subset = img_flat[indices]\n",
    "        \n",
    "        # Latent space distances\n",
    "        latent_distances = torch.cdist(z_subset, z_subset, p=2)\n",
    "        \n",
    "        # Image space distances\n",
    "        image_distances = torch.cdist(img_subset, img_subset, p=2)\n",
    "        \n",
    "        # Calculate correlation\n",
    "        latent_flat = latent_distances.flatten()\n",
    "        image_flat = image_distances.flatten()\n",
    "        \n",
    "        # Remove diagonal elements (self-distances)\n",
    "        mask = latent_flat > 0\n",
    "        latent_flat = latent_flat[mask]\n",
    "        image_flat = image_flat[mask]\n",
    "        \n",
    "        correlation = np.corrcoef(latent_flat.cpu().numpy(), image_flat.cpu().numpy())[0, 1]\n",
    "        \n",
    "        self.generator.train()\n",
    "        \n",
    "        return {\n",
    "            'latent_distances': latent_distances.cpu().numpy(),\n",
    "            'image_distances': image_distances.cpu().numpy(),\n",
    "            'correlation': correlation,\n",
    "            'latent_std': torch.std(z_flat).item(),\n",
    "            'image_std': torch.std(img_flat).item()\n",
    "        }\n",
    "\n",
    "def comprehensive_latent_space_exploration():\n",
    "    \"\"\"Perform comprehensive latent space exploration for all GANs.\"\"\"\n",
    "    print(\"üöÄ COMPREHENSIVE LATENT SPACE EXPLORATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Initialize explorers for both models\n",
    "    dcgan_explorer = LatentSpaceExplorer(dcgan.netG, dcgan.nz, device)\n",
    "    wgan_explorer = LatentSpaceExplorer(wgan_gp.netG, wgan_gp.nz, device)\n",
    "    \n",
    "    # Generate random points for interpolation\n",
    "    z1 = torch.randn(1, dcgan.nz, 1, 1, device=device)\n",
    "    z2 = torch.randn(1, dcgan.nz, 1, 1, device=device)\n",
    "    \n",
    "    # Latent space interpolation comparison\n",
    "    print(\"\\nüîÑ Latent Space Interpolation Analysis:\")\n",
    "    \n",
    "    # DCGAN interpolation\n",
    "    dcgan_interp = dcgan_explorer.interpolate_latent_space(z1, z2, num_steps=8)\n",
    "    \n",
    "    # WGAN-GP interpolation  \n",
    "    wgan_interp = wgan_explorer.interpolate_latent_space(z1, z2, num_steps=8)\n",
    "    \n",
    "    # Visualize interpolations\n",
    "    fig, axes = plt.subplots(2, 8, figsize=(20, 6))\n",
    "    \n",
    "    for i in range(8):\n",
    "        # DCGAN interpolation\n",
    "        img = dcgan_interp[i].cpu()\n",
    "        img = (img + 1) / 2  # Denormalize from [-1,1] to [0,1]\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        axes[0, i].imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
    "        axes[0, i].set_title(f'DCGAN\\nStep {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # WGAN-GP interpolation\n",
    "        img = wgan_interp[i].cpu()\n",
    "        img = (img + 1) / 2  # Denormalize from [-1,1] to [0,1]\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        axes[1, i].imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
    "        axes[1, i].set_title(f'WGAN-GP\\nStep {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Latent Space Interpolation Comparison', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(notebook_results_dir / 'analysis' / 'latent_interpolation_comparison.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Direction exploration\n",
    "    print(\"\\nüß≠ Random Direction Exploration:\")\n",
    "    \n",
    "    base_z = torch.randn(1, dcgan.nz, 1, 1, device=device)\n",
    "    random_direction = torch.randn(1, dcgan.nz, 1, 1, device=device)\n",
    "    random_direction = random_direction / torch.norm(random_direction)  # Normalize\n",
    "    \n",
    "    # Explore direction for both models\n",
    "    dcgan_direction, steps = dcgan_explorer.explore_latent_directions(base_z, random_direction)\n",
    "    wgan_direction, _ = wgan_explorer.explore_latent_directions(base_z, random_direction)\n",
    "    \n",
    "    # Visualize direction exploration\n",
    "    fig, axes = plt.subplots(2, len(steps), figsize=(18, 6))\n",
    "    \n",
    "    for i, step in enumerate(steps):\n",
    "        # DCGAN\n",
    "        img = dcgan_direction[i].cpu()\n",
    "        img = (img + 1) / 2\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        axes[0, i].imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
    "        axes[0, i].set_title(f'DCGAN\\nStep {step}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # WGAN-GP\n",
    "        img = wgan_direction[i].cpu()\n",
    "        img = (img + 1) / 2\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        axes[1, i].imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
    "        axes[1, i].set_title(f'WGAN-GP\\nStep {step}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Movement Along Random Latent Direction', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(notebook_results_dir / 'analysis' / 'latent_direction_exploration.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Latent space structure analysis\n",
    "    print(\"\\nüî¨ Latent Space Structure Analysis:\")\n",
    "    \n",
    "    dcgan_structure = dcgan_explorer.analyze_latent_space_structure(num_samples=300)\n",
    "    wgan_structure = wgan_explorer.analyze_latent_space_structure(num_samples=300)\n",
    "    \n",
    "    # Visualize structure analysis\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # DCGAN analysis\n",
    "    im1 = axes[0, 0].imshow(dcgan_structure['latent_distances'], cmap='viridis')\n",
    "    axes[0, 0].set_title('DCGAN Latent Space Distances')\n",
    "    axes[0, 0].set_xlabel('Sample Index')\n",
    "    axes[0, 0].set_ylabel('Sample Index')\n",
    "    plt.colorbar(im1, ax=axes[0, 0])\n",
    "    \n",
    "    im2 = axes[0, 1].imshow(dcgan_structure['image_distances'], cmap='plasma')\n",
    "    axes[0, 1].set_title('DCGAN Image Space Distances')\n",
    "    axes[0, 1].set_xlabel('Sample Index')\n",
    "    axes[0, 1].set_ylabel('Sample Index')\n",
    "    plt.colorbar(im2, ax=axes[0, 1])\n",
    "    \n",
    "    # Correlation plot for DCGAN\n",
    "    latent_flat = dcgan_structure['latent_distances'].flatten()\n",
    "    image_flat = dcgan_structure['image_distances'].flatten()\n",
    "    mask = latent_flat > 0\n",
    "    latent_flat = latent_flat[mask]\n",
    "    image_flat = image_flat[mask]\n",
    "    \n",
    "    axes[0, 2].scatter(latent_flat[:1000], image_flat[:1000], alpha=0.5, s=1)\n",
    "    axes[0, 2].set_xlabel('Latent Space Distance')\n",
    "    axes[0, 2].set_ylabel('Image Space Distance')\n",
    "    axes[0, 2].set_title(f'DCGAN Correlation: {dcgan_structure[\"correlation\"]:.3f}')\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # WGAN-GP analysis\n",
    "    im3 = axes[1, 0].imshow(wgan_structure['latent_distances'], cmap='viridis')\n",
    "    axes[1, 0].set_title('WGAN-GP Latent Space Distances')\n",
    "    axes[1, 0].set_xlabel('Sample Index')\n",
    "    axes[1, 0].set_ylabel('Sample Index')\n",
    "    plt.colorbar(im3, ax=axes[1, 0])\n",
    "    \n",
    "    im4 = axes[1, 1].imshow(wgan_structure['image_distances'], cmap='plasma')\n",
    "    axes[1, 1].set_title('WGAN-GP Image Space Distances')\n",
    "    axes[1, 1].set_xlabel('Sample Index')\n",
    "    axes[1, 1].set_ylabel('Sample Index')\n",
    "    plt.colorbar(im4, ax=axes[1, 1])\n",
    "    \n",
    "    # Correlation plot for WGAN-GP\n",
    "    latent_flat = wgan_structure['latent_distances'].flatten()\n",
    "    image_flat = wgan_structure['image_distances'].flatten()\n",
    "    mask = latent_flat > 0\n",
    "    latent_flat = latent_flat[mask]\n",
    "    image_flat = image_flat[mask]\n",
    "    \n",
    "    axes[1, 2].scatter(latent_flat[:1000], image_flat[:1000], alpha=0.5, s=1)\n",
    "    axes[1, 2].set_xlabel('Latent Space Distance')\n",
    "    axes[1, 2].set_ylabel('Image Space Distance')\n",
    "    axes[1, 2].set_title(f'WGAN-GP Correlation: {wgan_structure[\"correlation\"]:.3f}')\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(notebook_results_dir / 'analysis' / 'latent_space_structure_analysis.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print quantitative analysis\n",
    "    print(f\"\\nüìä Latent Space Quality Assessment:\")\n",
    "    print(f\"   DCGAN Latent-Image Correlation: {dcgan_structure['correlation']:.4f}\")\n",
    "    print(f\"   WGAN-GP Latent-Image Correlation: {wgan_structure['correlation']:.4f}\")\n",
    "    \n",
    "    # Interpret correlation values\n",
    "    def interpret_correlation(corr, model_name):\n",
    "        if corr > 0.6:\n",
    "            return f\"‚úÖ {model_name}: Excellent latent space structure\"\n",
    "        elif corr > 0.4:\n",
    "            return f\"‚ö†Ô∏è {model_name}: Good latent space structure\"\n",
    "        elif corr > 0.2:\n",
    "            return f\"‚ö†Ô∏è {model_name}: Moderate latent space structure\"\n",
    "        else:\n",
    "            return f\"‚ùå {model_name}: Poor latent space structure\"\n",
    "    \n",
    "    print(f\"   {interpret_correlation(dcgan_structure['correlation'], 'DCGAN')}\")\n",
    "    print(f\"   {interpret_correlation(wgan_structure['correlation'], 'WGAN-GP')}\")\n",
    "    \n",
    "    # Random walk exploration\n",
    "    print(f\"\\nüö∂ Random Walk Exploration:\")\n",
    "    \n",
    "    start_z = torch.randn(1, dcgan.nz, 1, 1, device=device)\n",
    "    \n",
    "    dcgan_walk = dcgan_explorer.random_walk(start_z, num_steps=8, step_size=0.3)\n",
    "    wgan_walk = wgan_explorer.random_walk(start_z, num_steps=8, step_size=0.3)\n",
    "    \n",
    "    # Visualize random walks\n",
    "    fig, axes = plt.subplots(2, 8, figsize=(20, 6))\n",
    "    \n",
    "    for i in range(8):\n",
    "        # DCGAN walk\n",
    "        img = dcgan_walk[i].cpu()\n",
    "        img = (img + 1) / 2\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        axes[0, i].imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
    "        axes[0, i].set_title(f'DCGAN\\nStep {i+1}')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # WGAN-GP walk\n",
    "        img = wgan_walk[i].cpu()\n",
    "        img = (img + 1) / 2\n",
    "        img = torch.clamp(img, 0, 1)\n",
    "        axes[1, i].imshow(np.transpose(img.numpy(), (1, 2, 0)))\n",
    "        axes[1, i].set_title(f'WGAN-GP\\nStep {i+1}')\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Random Walk in Latent Space', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(notebook_results_dir / 'analysis' / 'latent_random_walk.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'dcgan_structure': dcgan_structure,\n",
    "        'wgan_structure': wgan_structure\n",
    "    }\n",
    "\n",
    "# Perform comprehensive latent space exploration\n",
    "latent_analysis_results = comprehensive_latent_space_exploration()\n",
    "\n",
    "print(\"‚úÖ Comprehensive latent space exploration completed!\")\n",
    "```\n",
    "\n",
    "## 8. GAN Evaluation Metrics and Final Analysis\n",
    "\n",
    "Implementation of comprehensive evaluation metrics and final comparative analysis of all GAN variants.\n",
    "\n",
    "```python\n",
    "class GANEvaluationSuite:\n",
    "    \"\"\"\n",
    "    Comprehensive GAN evaluation metrics and analysis toolkit.\n",
    "    \n",
    "    Implements various evaluation metrics including:\n",
    "    - Inception Score (simplified)\n",
    "    - Fr√©chet Inception Distance (simplified)\n",
    "    - Mode collapse detection\n",
    "    - Diversity metrics\n",
    "    - Quality assessments\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.metrics_computed = {}\n",
    "        \n",
    "    def inception_score_simplified(self, generated_images, num_splits=10):\n",
    "        \"\"\"Simplified Inception Score calculation.\"\"\"\n",
    "        batch_size = generated_images.size(0)\n",
    "        \n",
    "        # Convert to numpy for easier computation\n",
    "        images = generated_images.cpu().numpy()\n",
    "        \n",
    "        # Simple diversity metric based on pixel variance across samples\n",
    "        pixel_variance = np.var(images.reshape(batch_size, -1), axis=0)\n",
    "        diversity_score = np.mean(pixel_variance)\n",
    "        \n",
    "        # Simple quality metric based on image statistics\n",
    "        mean_intensity = np.mean(images)\n",
    "        std_intensity = np.std(images)\n",
    "        \n",
    "        # Combine diversity and quality (simplified IS approximation)\n",
    "        quality_factor = 1.0 / (1.0 + abs(mean_intensity))\n",
    "        is_score = diversity_score * quality_factor * 100  # Scale for readability\n",
    "        \n",
    "        return is_score\n",
    "    \n",
    "    def frechet_distance_simplified(self, real_images, generated_images):\n",
    "        \"\"\"Simplified Fr√©chet Inception Distance calculation.\"\"\"\n",
    "        # Flatten images\n",
    "        real_flat = real_images.view(real_images.size(0), -1).cpu().numpy()\n",
    "        gen_flat = generated_images.view(generated_images.size(0), -1).cpu().numpy()\n",
    "        \n",
    "        # Calculate means\n",
    "        real_mean = np.mean(real_flat, axis=0)\n",
    "        gen_mean = np.mean(gen_flat, axis=0)\n",
    "        \n",
    "        # Calculate covariances\n",
    "        real_cov = np.cov(real_flat, rowvar=False)\n",
    "        gen_cov = np.cov(gen_flat, rowvar=False)\n",
    "        \n",
    "        # Simplified FID calculation (using Frobenius norm difference)\n",
    "        mean_diff = np.linalg.norm(real_mean - gen_mean)\n",
    "        cov_diff = np.linalg.norm(real_cov - gen_cov, ord='fro')\n",
    "        \n",
    "        simplified_fid = mean_diff + 0.1 * cov_diff  # Weighted combination\n",
    "        \n",
    "        return simplified_fid\n",
    "    \n",
    "    def mode_collapse_detection(self, generator, num_samples=1000, threshold=0.05):\n",
    "        \"\"\"Detect potential mode collapse by analyzing sample diversity.\"\"\"\n",
    "        generator.eval()\n",
    "        \n",
    "        # Generate samples\n",
    "        with torch.no_grad():\n",
    "            if hasattr(generator, 'nz'):\n",
    "                noise = torch.randn(num_samples, generator.nz, 1, 1, device=device)\n",
    "            else:\n",
    "                noise = torch.randn(num_samples, 100, 1, 1, device=device)\n",
    "            samples = generator(noise)\n",
    "        \n",
    "        # Flatten for distance calculation\n",
    "        samples_flat = samples.view(num_samples, -1)\n",
    "        \n",
    "        # Calculate pairwise distances efficiently (sample subset)\n",
    "        subset_size = min(200, num_samples)\n",
    "        indices = torch.randperm(num_samples)[:subset_size]\n",
    "        subset = samples_flat[indices]\n",
    "        \n",
    "        distances = torch.cdist(subset, subset, p=2)\n",
    "        \n",
    "        # Count very similar samples\n",
    "        similar_pairs = (distances < threshold).sum().item() - subset_size  # Exclude diagonal\n",
    "        total_pairs = subset_size * (subset_size - 1)\n",
    "        \n",
    "        collapse_ratio = similar_pairs / total_pairs\n",
    "        avg_distance = distances.mean().item()\n",
    "        \n",
    "        generator.train()\n",
    "        \n",
    "        return collapse_ratio, avg_distance\n",
    "    \n",
    "    def diversity_score(self, generated_images):\n",
    "        \"\"\"Calculate diversity score based on pairwise image differences.\"\"\"\n",
    "        batch_size = generated_images.size(0)\n",
    "        \n",
    "        # Flatten images\n",
    "        images_flat = generated_images.view(batch_size, -1)\n",
    "        \n",
    "        # Calculate pairwise distances\n",
    "        distances = torch.cdist(images_flat, images_flat, p=2)\n",
    "        \n",
    "        # Average distance (excluding diagonal)\n",
    "        mask = torch.eye(batch_size, device=generated_images.device) == 0\n",
    "        avg_distance = distances[mask].mean().item()\n",
    "        \n",
    "        return avg_distance\n",
    "    \n",
    "    def image_quality_metrics(self, images):\n",
    "        \"\"\"Calculate various image quality metrics.\"\"\"\n",
    "        # Convert to numpy for easier computation\n",
    "        images_np = images.cpu().numpy()\n",
    "        \n",
    "        # Intensity statistics\n",
    "        mean_intensity = np.mean(images_np)\n",
    "        std_intensity = np.std(images_np)\n",
    "        \n",
    "        # Contrast measure (simplified)\n",
    "        contrast = std_intensity / (mean_intensity + 1e-8)\n",
    "        \n",
    "        # Sharpness measure (gradient magnitude)\n",
    "        grad_x = np.gradient(images_np, axis=-1)\n",
    "        grad_y = np.gradient(images_np, axis=-2)\n",
    "        sharpness = np.mean(np.sqrt(grad_x**2 + grad_y**2))\n",
    "        \n",
    "        return {\n",
    "            'mean_intensity': mean_intensity,\n",
    "            'std_intensity': std_intensity,\n",
    "            'contrast': contrast,\n",
    "            'sharpness': sharpness\n",
    "        }\n",
    "    \n",
    "    def comprehensive_evaluation(self, generator, real_dataloader, model_name, num_samples=1000):\n",
    "        \"\"\"Perform comprehensive evaluation of a generator.\"\"\"\n",
    "        print(f\"\\nüî¨ Evaluating {model_name}...\")\n",
    "        \n",
    "        generator.eval()\n",
    "        \n",
    "        # Generate samples\n",
    "        with torch.no_grad():\n",
    "            if hasattr(generator, 'nz'):\n",
    "                noise = torch.randn(num_samples, generator.nz, 1, 1, device=device)\n",
    "            else:\n",
    "                noise = torch.randn(num_samples, 100, 1, 1, device=device)\n",
    "            generated_samples = generator(noise)\n",
    "        \n",
    "        # Get real samples for comparison\n",
    "        real_samples = []\n",
    "        for i, batch in enumerate(real_dataloader):\n",
    "            real_samples.append(batch)\n",
    "            if len(real_samples) * batch.size(0) >= num_samples:\n",
    "                break\n",
    "        \n",
    "        real_samples = torch.cat(real_samples, dim=0)[:num_samples]\n",
    "        \n",
    "        # Calculate all metrics\n",
    "        metrics = {}\n",
    "        \n",
    "        # Inception Score (simplified)\n",
    "        metrics['inception_score'] = self.inception_score_simplified(generated_samples)\n",
    "        \n",
    "        # Fr√©chet Distance (simplified)\n",
    "        metrics['fid_score'] = self.frechet_distance_simplified(real_samples, generated_samples)\n",
    "        \n",
    "        # Mode collapse detection\n",
    "        collapse_ratio, avg_distance = self.mode_collapse_detection(generator)\n",
    "        metrics['mode_collapse_ratio'] = collapse_ratio\n",
    "        metrics['average_distance'] = avg_distance\n",
    "        \n",
    "        # Diversity score\n",
    "        metrics['diversity_score'] = self.diversity_score(generated_samples)\n",
    "        \n",
    "        # Image quality metrics\n",
    "        quality_metrics = self.image_quality_metrics(generated_samples)\n",
    "        metrics.update(quality_metrics)\n",
    "        \n",
    "        # Real vs generated statistics comparison\n",
    "        real_quality = self.image_quality_metrics(real_samples)\n",
    "        metrics['intensity_similarity'] = abs(metrics['mean_intensity'] - real_quality['mean_intensity'])\n",
    "        metrics['contrast_similarity'] = abs(metrics['contrast'] - real_quality['contrast'])\n",
    "        \n",
    "        generator.train()\n",
    "        \n",
    "        return metrics\n",
    "\n",
    "def final_comprehensive_evaluation():\n",
    "    \"\"\"Perform final comprehensive evaluation of all GAN models.\"\"\"\n",
    "    print(\"üìä FINAL COMPREHENSIVE EVALUATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    evaluator = GANEvaluationSuite()\n",
    "    \n",
    "    # Evaluate DCGAN\n",
    "    dcgan_metrics = evaluator.comprehensive_evaluation(dcgan.netG, img_dataloader, 'DCGAN')\n",
    "    \n",
    "    # Evaluate WGAN-GP\n",
    "    wgan_metrics = evaluator.comprehensive_evaluation(wgan_gp.netG, img_dataloader, 'WGAN-GP')\n",
    "    \n",
    "    # Create comprehensive evaluation visualization\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "    \n",
    "    # 1. Inception Score Comparison\n",
    "    models = ['DCGAN', 'WGAN-GP']\n",
    "    is_scores = [dcgan_metrics['inception_score'], wgan_metrics['inception_score']]\n",
    "    \n",
    "    bars1 = axes[0, 0].bar(models, is_scores, alpha=0.8, color=['skyblue', 'lightgreen'])\n",
    "    axes[0, 0].set_ylabel('Inception Score (Simplified)')\n",
    "    axes[0, 0].set_title('Inception Score Comparison')\n",
    "    for bar, score in zip(bars1, is_scores):\n",
    "        height = bar.get_height()\n",
    "        axes[0, 0].text(bar.get_x() + bar.get_width()/2., height + max(is_scores)*0.01,\n",
    "                        f'{score:.2f}', ha='center', va='bottom')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. FID Score Comparison (lower is better)\n",
    "    fid_scores = [dcgan_metrics['fid_score'], wgan_metrics['fid_score']]\n",
    "    \n",
    "    bars2 = axes[0, 1].bar(models, fid_scores, alpha=0.8, color=['orange', 'purple'])\n",
    "    axes[0, 1].set_ylabel('FID Score (Simplified)')\n",
    "    axes[0, 1].set_title('FID Score Comparison (Lower is Better)')\n",
    "    for bar, score in zip(bars2, fid_scores):\n",
    "        height = bar.get_height()\n",
    "        axes[0, 1].text(bar.get_x() + bar.get_width()/2., height + max(fid_scores)*0.01,\n",
    "                        f'{score:.2f}', ha='center', va='bottom')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Mode Collapse Detection\n",
    "    collapse_ratios = [dcgan_metrics['mode_collapse_ratio'], wgan_metrics['mode_collapse_ratio']]\n",
    "    \n",
    "    bars3 = axes[0, 2].bar(models, collapse_ratios, alpha=0.8, color=['red', 'pink'])\n",
    "    axes[0, 2].set_ylabel('Mode Collapse Ratio')\n",
    "    axes[0, 2].set_title('Mode Collapse Detection (Lower is Better)')\n",
    "    for bar, ratio in zip(bars3, collapse_ratios):\n",
    "        height = bar.get_height()\n",
    "        axes[0, 2].text(bar.get_x() + bar.get_width()/2., height + max(collapse_ratios)*0.01,\n",
    "                        f'{ratio:.4f}', ha='center', va='bottom')\n",
    "    axes[0, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Diversity Score Comparison\n",
    "    diversity_scores = [dcgan_metrics['diversity_score'], wgan_metrics['diversity_score']]\n",
    "    \n",
    "    bars4 = axes[1, 0].bar(models, diversity_scores, alpha=0.8, color=['gold', 'lightcoral'])\n",
    "    axes[1, 0].set_ylabel('Diversity Score')\n",
    "    axes[1, 0].set_title('Sample Diversity Comparison')\n",
    "    for bar, score in zip(bars4, diversity_scores):\n",
    "        height = bar.get_height()\n",
    "        axes[1, 0].text(bar.get_x() + bar.get_width()/2., height + max(diversity_scores)*0.01,\n",
    "                        f'{score:.2f}', ha='center', va='bottom')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Image Quality Metrics\n",
    "    quality_metrics = ['mean_intensity', 'contrast', 'sharpness']\n",
    "    dcgan_quality = [dcgan_metrics[metric] for metric in quality_metrics]\n",
    "    wgan_quality = [wgan_metrics[metric] for metric in quality_metrics]\n",
    "    \n",
    "    x = np.arange(len(quality_metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[1, 1].bar(x - width/2, dcgan_quality, width, label='DCGAN', alpha=0.8, color='skyblue')\n",
    "    axes[1, 1].bar(x + width/2, wgan_quality, width, label='WGAN-GP', alpha=0.8, color='lightgreen')\n",
    "    axes[1, 1].set_ylabel('Value')\n",
    "    axes[1, 1].set_title('Image Quality Metrics')\n",
    "    axes[1, 1].set_xticks(x)\n",
    "    axes[1, 1].set_xticklabels([m.replace('_', ' ').title() for m in quality_metrics])\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Final Generated Samples Comparison\n",
    "    axes[1, 2].set_title('Final Generated Samples')\n",
    "    \n",
    "    # Create side-by-side comparison\n",
    "    dcgan_final_samples = dcgan.generate_samples(8)\n",
    "    wgan_final_samples = wgan_gp.generate_samples(8)\n",
    "    \n",
    "    # Combine samples for display\n",
    "    combined_samples = torch.cat([dcgan_final_samples[:4], wgan_final_samples[:4]], dim=0)\n",
    "    grid = vutils.make_grid(combined_samples, padding=2, normalize=True, nrow=4)\n",
    "    axes[1, 2].imshow(np.transpose(grid.cpu().numpy(), (1, 2, 0)))\n",
    "    axes[1, 2].axis('off')\n",
    "    axes[1, 2].text(0.25, -0.05, 'DCGAN', transform=axes[1, 2].transAxes, ha='center', fontsize=12)\n",
    "    axes[1, 2].text(0.75, -0.05, 'WGAN-GP', transform=axes[1, 2].transAxes, ha='center', fontsize=12)\n",
    "    \n",
    "    # 7. Comprehensive Metrics Summary\n",
    "    summary_metrics = {\n",
    "        'DCGAN': {\n",
    "            'Inception Score': dcgan_metrics['inception_score'],\n",
    "            'FID Score': dcgan_metrics['fid_score'],\n",
    "            'Mode Collapse': dcgan_metrics['mode_collapse_ratio'],\n",
    "            'Diversity': dcgan_metrics['diversity_score'],\n",
    "            'Quality': np.mean([dcgan_metrics['contrast'], dcgan_metrics['sharpness']])\n",
    "        },\n",
    "        'WGAN-GP': {\n",
    "            'Inception Score': wgan_metrics['inception_score'],\n",
    "            'FID Score': wgan_metrics['fid_score'],\n",
    "            'Mode Collapse': wgan_metrics['mode_collapse_ratio'],\n",
    "            'Diversity': wgan_metrics['diversity_score'],\n",
    "            'Quality': np.mean([wgan_metrics['contrast'], wgan_metrics['sharpness']])\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Create radar chart for comprehensive comparison\n",
    "    metrics_names = list(summary_metrics['DCGAN'].keys())\n",
    "    dcgan_values = list(summary_metrics['DCGAN'].values())\n",
    "    wgan_values = list(summary_metrics['WGAN-GP'].values())\n",
    "    \n",
    "    # Normalize values for radar chart (0-1 scale)\n",
    "    max_values = [max(dcgan_values[i], wgan_values[i]) for i in range(len(metrics_names))]\n",
    "    dcgan_norm = [dcgan_values[i] / max_values[i] for i in range(len(metrics_names))]\n",
    "    wgan_norm = [wgan_values[i] / max_values[i] for i in range(len(metrics_names))]\n",
    "    \n",
    "    # For metrics where lower is better (FID, Mode Collapse), invert normalization\n",
    "    invert_metrics = [1, 2]  # FID Score, Mode Collapse\n",
    "    for i in invert_metrics:\n",
    "        dcgan_norm[i] = 1 - dcgan_norm[i]\n",
    "        wgan_norm[i] = 1 - wgan_norm[i]\n",
    "    \n",
    "    angles = np.linspace(0, 2 * np.pi, len(metrics_names), endpoint=False)\n",
    "    angles = np.concatenate((angles, [angles[0]]))\n",
    "    \n",
    "    dcgan_norm.append(dcgan_norm[0])\n",
    "    wgan_norm.append(wgan_norm[0])\n",
    "    \n",
    "    ax_radar = plt.subplot(2, 3, 8, projection='polar')\n",
    "    ax_radar.plot(angles, dcgan_norm, 'o-', linewidth=2, label='DCGAN', color='skyblue')\n",
    "    ax_radar.fill(angles, dcgan_norm, alpha=0.25, color='skyblue')\n",
    "    ax_radar.plot(angles, wgan_norm, 'o-', linewidth=2, label='WGAN-GP', color='lightgreen')\n",
    "    ax_radar.fill(angles, wgan_norm, alpha=0.25, color='lightgreen')\n",
    "    \n",
    "    ax_radar.set_xticks(angles[:-1])\n",
    "    ax_radar.set_xticklabels(metrics_names)\n",
    "    ax_radar.set_ylim(0, 1)\n",
    "    ax_radar.set_title('Comprehensive Performance Radar', pad=20)\n",
    "    ax_radar.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))\n",
    "    \n",
    "    # 8. Final Recommendations\n",
    "    recommendations_text = \"EVALUATION SUMMARY & RECOMMENDATIONS\\n\\n\"\n",
    "    \n",
    "    # Determine winners for each metric\n",
    "    if dcgan_metrics['inception_score'] > wgan_metrics['inception_score']:\n",
    "        recommendations_text += \"‚Ä¢ Inception Score: DCGAN performs better\\n\"\n",
    "    else:\n",
    "        recommendations_text += \"‚Ä¢ Inception Score: WGAN-GP performs better\\n\"\n",
    "    \n",
    "    if dcgan_metrics['fid_score'] < wgan_metrics['fid_score']:\n",
    "        recommendations_text += \"‚Ä¢ FID Score: DCGAN performs better (lower FID)\\n\"\n",
    "    else:\n",
    "        recommendations_text += \"‚Ä¢ FID Score: WGAN-GP performs better (lower FID)\\n\"\n",
    "    \n",
    "    if dcgan_metrics['mode_collapse_ratio'] < wgan_metrics['mode_collapse_ratio']:\n",
    "        recommendations_text += \"‚Ä¢ Mode Collapse: DCGAN shows less collapse\\n\"\n",
    "    else:\n",
    "        recommendations_text += \"‚Ä¢ Mode Collapse: WGAN-GP shows less collapse\\n\"\n",
    "    \n",
    "    recommendations_text += f\"\\nTraining Stability: {quantitative_results['stability_winner']} is more stable\\n\"\n",
    "    recommendations_text += f\"\\nLatent Space Quality:\\n\"\n",
    "    recommendations_text += f\"  DCGAN: {latent_analysis_results['dcgan_structure']['correlation']:.3f}\\n\"\n",
    "    recommendations_text += f\"  WGAN-GP: {latent_analysis_results['wgan_structure']['correlation']:.3f}\\n\"\n",
    "    \n",
    "    if latent_analysis_results['dcgan_structure']['correlation'] > latent_analysis_results['wgan_structure']['correlation']:\n",
    "        recommendations_text += \"  DCGAN has better latent structure\\n\"\n",
    "    else:\n",
    "        recommendations_text += \"  WGAN-GP has better latent structure\\n\"\n",
    "    \n",
    "    recommendations_text += \"\\nOVERALL RECOMMENDATION:\\n\"\n",
    "    \n",
    "    # Count wins for each model\n",
    "    dcgan_wins = 0\n",
    "    wgan_wins = 0\n",
    "    \n",
    "    if dcgan_metrics['inception_score'] > wgan_metrics['inception_score']:\n",
    "        dcgan_wins += 1\n",
    "    else:\n",
    "        wgan_wins += 1\n",
    "        \n",
    "    if dcgan_metrics['fid_score'] < wgan_metrics['fid_score']:\n",
    "        dcgan_wins += 1\n",
    "    else:\n",
    "        wgan_wins += 1\n",
    "        \n",
    "    if quantitative_results['stability_winner'] == 'DCGAN':\n",
    "        dcgan_wins += 1\n",
    "    else:\n",
    "        wgan_wins += 1\n",
    "    \n",
    "    if dcgan_wins > wgan_wins:\n",
    "        recommendations_text += \"üèÜ DCGAN shows better overall performance\"\n",
    "    elif wgan_wins > dcgan_wins:\n",
    "        recommendations_text += \"üèÜ WGAN-GP shows better overall performance\"\n",
    "    else:\n",
    "        recommendations_text += \"ü§ù Both models show comparable performance\"\n",
    "    \n",
    "    axes[2, 2].text(0.05, 0.95, recommendations_text, transform=axes[2, 2].transAxes, \n",
    "                   fontsize=9, verticalalignment='top', fontfamily='monospace',\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "    axes[2, 2].set_title('Final Evaluation Summary')\n",
    "    axes[2, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(notebook_results_dir / 'analysis' / 'final_comprehensive_evaluation.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'dcgan_metrics': dcgan_metrics,\n",
    "        'wgan_metrics': wgan_metrics,\n",
    "        'summary_metrics': summary_metrics\n",
    "    }\n",
    "\n",
    "# Perform final comprehensive evaluation\n",
    "final_evaluation_results = final_comprehensive_evaluation()\n",
    "\n",
    "print(\"‚úÖ Final comprehensive evaluation completed!\")\n",
    "```\n",
    "\n",
    "## 9. Results Summary and Model Persistence\n",
    "\n",
    "Save all models, generate comprehensive reports, and provide final recommendations.\n",
    "\n",
    "```python\n",
    "def save_comprehensive_results():\n",
    "    \"\"\"Save all models, results, and generate comprehensive reports.\"\"\"\n",
    "    print(\"üíæ SAVING COMPREHENSIVE RESULTS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Save trained models\n",
    "    print(\"\\nüì¶ Saving Trained Models:\")\n",
    "    \n",
    "    # Save DCGAN\n",
    "    torch.save({\n",
    "        'generator_state_dict': dcgan.netG.state_dict(),\n",
    "        'discriminator_state_dict': dcgan.netD.state_dict(),\n",
    "        'generator_optimizer': dcgan.optimizerG.state_dict(),\n",
    "        'discriminator_optimizer': dcgan.optimizerD.state_dict(),\n",
    "        'training_history': dcgan.history,\n",
    "        'hyperparameters': {\n",
    "            'nz': dcgan.nz,\n",
    "            'lr': dcgan.lr,\n",
    "            'beta1': dcgan.beta1\n",
    "        }\n",
    "    }, notebook_results_dir / 'models' / 'dcgan_complete.pth')\n",
    "    \n",
    "    # Save WGAN-GP\n",
    "    torch.save({\n",
    "        'generator_state_dict': wgan_gp.netG.state_dict(),\n",
    "        'critic_state_dict': wgan_gp.netC.state_dict(),\n",
    "        'generator_optimizer': wgan_gp.optimizerG.state_dict(),\n",
    "        'critic_optimizer': wgan_gp.optimizerC.state_dict(),\n",
    "        'training_history': wgan_gp.history,\n",
    "        'hyperparameters': {\n",
    "            'nz': wgan_gp.nz,\n",
    "            'lr': wgan_gp.lr,\n",
    "            'lambda_gp': wgan_gp.lambda_gp,\n",
    "            'n_critic': wgan_gp.n_critic\n",
    "        }\n",
    "    }, notebook_results_dir / 'models' / 'wgan_gp_complete.pth')\n",
    "    \n",
    "    # Save Vanilla GAN\n",
    "    torch.save({\n",
    "        'generator_state_dict': vanilla_gan.generator.state_dict(),\n",
    "        'discriminator_state_dict': vanilla_gan.discriminator.state_dict(),\n",
    "        'generator_optimizer': vanilla_gan.g_optimizer.state_dict(),\n",
    "        'discriminator_optimizer': vanilla_gan.d_optimizer.state_dict(),\n",
    "        'training_history': vanilla_gan.history,\n",
    "        'hyperparameters': {\n",
    "            'latent_dim': vanilla_gan.latent_dim,\n",
    "            'data_dim': vanilla_gan.data_dim\n",
    "        }\n",
    "    }, notebook_results_dir / 'models' / 'vanilla_gan_complete.pth')\n",
    "    \n",
    "    print(\"   ‚úÖ DCGAN model saved\")\n",
    "    print(\"   ‚úÖ WGAN-GP model saved\") \n",
    "    print(\"   ‚úÖ Vanilla GAN model saved\")\n",
    "    \n",
    "    # Compile comprehensive results\n",
    "    comprehensive_results = {\n",
    "        'experiment_info': {\n",
    "            'date': pd.Timestamp.now().isoformat(),\n",
    "            'device': str(device),\n",
    "            'pytorch_version': torch.__version__,\n",
    "            'models_trained': ['Vanilla GAN', 'DCGAN', 'WGAN-GP']\n",
    "        },\n",
    "        'vanilla_gan': {\n",
    "            'architecture': 'Fully Connected',\n",
    "            'dataset': 'Gaussian Mixture 2D',\n",
    "            'training_epochs': len(vanilla_gan.history['epochs']),\n",
    "            'final_metrics': {\n",
    "                'generator_loss': vanilla_gan.history['g_loss'][-1],\n",
    "                'discriminator_loss': vanilla_gan.history['d_loss'][-1],\n",
    "                'real_accuracy': vanilla_gan.history['real_acc'][-1],\n",
    "                'fake_accuracy': vanilla_gan.history['fake_acc'][-1]\n",
    "            }\n",
    "        },\n",
    "        'dcgan': {\n",
    "            'architecture': 'Deep Convolutional',\n",
    "            'dataset': 'Synthetic Images 64x64',\n",
    "            'training_epochs': len(dcgan.history['epochs']),\n",
    "            'parameters': {\n",
    "                'generator': dcgan.netG.total_params,\n",
    "                'discriminator': dcgan.netD.total_params\n",
    "            },\n",
    "            'final_metrics': training_analysis_results['DCGAN'],\n",
    "            'evaluation_metrics': final_evaluation_results['dcgan_metrics']\n",
    "        },\n",
    "        'wgan_gp': {\n",
    "            'architecture': 'Wasserstein with Gradient Penalty',\n",
    "            'dataset': 'Synthetic Images 64x64',\n",
    "            'training_epochs': len(wgan_gp.history['epochs']),\n",
    "            'parameters': {\n",
    "                'generator': wgan_gp.netG.total_params,\n",
    "                'critic': wgan_gp.netC.total_params\n",
    "            },\n",
    "            'final_metrics': training_analysis_results['WGAN-GP'],\n",
    "            'evaluation_metrics': final_evaluation_results['wgan_metrics']\n",
    "        },\n",
    "        'comparative_analysis': {\n",
    "            'training_stability': quantitative_results,\n",
    "            'latent_space_quality': latent_analysis_results,\n",
    "            'evaluation_summary': final_evaluation_results['summary_metrics']\n",
    "        },\n",
    "        'recommendations': {\n",
    "            'best_overall': determine_best_model(),\n",
    "            'use_cases': {\n",
    "                'research_stability': 'WGAN-GP for stable training',\n",
    "                'quick_prototyping': 'DCGAN for fast results',\n",
    "                'educational_purposes': 'Vanilla GAN for understanding concepts'\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    with open(notebook_results_dir / 'comprehensive_results.json', 'w') as f:\n",
    "        json.dump(comprehensive_results, f, indent=2, default=str)\n",
    "    \n",
    "    # Generate final report\n",
    "    generate_final_report(comprehensive_results)\n",
    "    \n",
    "    print(f\"\\nüìä Results Summary:\")\n",
    "    print(f\"   üìÅ Models saved to: {notebook_results_dir / 'models'}\")\n",
    "    print(f\"   üìà Analysis plots saved to: {notebook_results_dir / 'analysis'}\")\n",
    "    print(f\"   üñºÔ∏è Generated images saved to: {notebook_results_dir / 'generated_images'}\")\n",
    "    print(f\"   üìÑ Comprehensive results: {notebook_results_dir / 'comprehensive_results.json'}\")\n",
    "    \n",
    "    return comprehensive_results\n",
    "\n",
    "def determine_best_model():\n",
    "    \"\"\"Determine the best performing model based on all metrics.\"\"\"\n",
    "    scores = {'DCGAN': 0, 'WGAN-GP': 0}\n",
    "    \n",
    "    # Training stability (WGAN-GP typically wins)\n",
    "    if quantitative_results['stability_winner'] == 'WGAN-GP':\n",
    "        scores['WGAN-GP'] += 1\n",
    "    else:\n",
    "        scores['DCGAN'] += 1\n",
    "    \n",
    "    # Latent space quality\n",
    "    dcgan_corr = latent_analysis_results['dcgan_structure']['correlation']\n",
    "    wgan_corr = latent_analysis_results['wgan_structure']['correlation']\n",
    "    if dcgan_corr > wgan_corr:\n",
    "        scores['DCGAN'] += 1\n",
    "    else:\n",
    "        scores['WGAN-GP'] += 1\n",
    "    \n",
    "    # Evaluation metrics\n",
    "    dcgan_metrics = final_evaluation_results['dcgan_metrics']\n",
    "    wgan_metrics = final_evaluation_results['wgan_metrics']\n",
    "    \n",
    "    # Inception Score (higher is better)\n",
    "    if dcgan_metrics['inception_score'] > wgan_metrics['inception_score']:\n",
    "        scores['DCGAN'] += 1\n",
    "    else:\n",
    "        scores['WGAN-GP'] += 1\n",
    "    \n",
    "    # FID Score (lower is better)\n",
    "    if dcgan_metrics['fid_score'] < wgan_metrics['fid_score']:\n",
    "        scores['DCGAN'] += 1\n",
    "    else:\n",
    "        scores['WGAN-GP'] += 1\n",
    "    \n",
    "    # Mode collapse (lower is better)\n",
    "    if dcgan_metrics['mode_collapse_ratio'] < wgan_metrics['mode_collapse_ratio']:\n",
    "        scores['DCGAN'] += 1\n",
    "    else:\n",
    "        scores['WGAN-GP'] += 1\n",
    "    \n",
    "    if scores['DCGAN'] > scores['WGAN-GP']:\n",
    "        return 'DCGAN'\n",
    "    elif scores['WGAN-GP'] > scores['DCGAN']:\n",
    "        return 'WGAN-GP'\n",
    "    else:\n",
    "        return 'Tie - Both models show comparable performance'\n",
    "\n",
    "def generate_final_report(results):\n",
    "    \"\"\"Generate a comprehensive final report.\"\"\"\n",
    "    report_path = notebook_results_dir / 'GAN_Fundamentals_Final_Report.md'\n",
    "    \n",
    "    report_content = f\"\"\"# GAN Fundamentals: Complete Implementation and Analysis Report\n",
    "\n",
    "**Generated on:** {results['experiment_info']['date']}  \n",
    "**Environment:** {results['experiment_info']['device']}, PyTorch {results['experiment_info']['pytorch_version']}\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This comprehensive analysis implemented and compared three fundamental GAN architectures:\n",
    "- **Vanilla GAN** on 2D synthetic data for theoretical understanding\n",
    "- **DCGAN** on synthetic images for practical image generation\n",
    "- **WGAN-GP** for improved training stability and theoretical foundations\n",
    "\n",
    "## Model Performance Summary\n",
    "\n",
    "### 1. Vanilla GAN (2D Data)\n",
    "- **Architecture:** Fully connected networks\n",
    "- **Training Epochs:** {results['vanilla_gan']['training_epochs']}\n",
    "- **Final Generator Loss:** {results['vanilla_gan']['final_metrics']['generator_loss']:.4f}\n",
    "- **Final Discriminator Loss:** {results['vanilla_gan']['final_metrics']['discriminator_loss']:.4f}\n",
    "- **Training Balance:** {abs(results['vanilla_gan']['final_metrics']['real_accuracy'] - 0.5) + abs(results['vanilla_gan']['final_metrics']['fake_accuracy'] - 0.5):.4f}\n",
    "\n",
    "### 2. DCGAN (Image Generation)\n",
    "- **Architecture:** Deep Convolutional Networks\n",
    "- **Parameters:** {results['dcgan']['parameters']['generator']:,} (G) + {results['dcgan']['parameters']['discriminator']:,} (D)\n",
    "- **Training Epochs:** {results['dcgan']['training_epochs']}\n",
    "- **Final Generator Loss:** {results['dcgan']['final_metrics']['G_Loss']:.4f}\n",
    "- **Final Discriminator Loss:** {results['dcgan']['final_metrics']['D_Loss']:.4f}\n",
    "- **Training Balance Score:** {results['dcgan']['final_metrics']['Balance']:.4f}\n",
    "\n",
    "**Evaluation Metrics:**\n",
    "- Inception Score: {results['dcgan']['evaluation_metrics']['inception_score']:.2f}\n",
    "- FID Score: {results['dcgan']['evaluation_metrics']['fid_score']:.2f}\n",
    "- Mode Collapse Ratio: {results['dcgan']['evaluation_metrics']['mode_collapse_ratio']:.4f}\n",
    "- Diversity Score: {results['dcgan']['evaluation_metrics']['diversity_score']:.2f}\n",
    "\n",
    "### 3. WGAN-GP (Wasserstein Distance)\n",
    "- **Architecture:** Wasserstein GAN with Gradient Penalty\n",
    "- **Parameters:** {results['wgan_gp']['parameters']['generator']:,} (G) + {results['wgan_gp']['parameters']['critic']:,} (C)\n",
    "- **Training Epochs:** {results['wgan_gp']['training_epochs']}\n",
    "- **Final Generator Loss:** {results['wgan_gp']['final_metrics']['G_Loss']:.4f}\n",
    "- **Final Critic Loss:** {results['wgan_gp']['final_metrics']['C_Loss']:.4f}\n",
    "- **Wasserstein Distance:** {results['wgan_gp']['final_metrics']['W_Distance']:.4f}\n",
    "- **Gradient Penalty:** {results['wgan_gp']['final_metrics']['Grad_Penalty']:.4f}\n",
    "\n",
    "**Evaluation Metrics:**\n",
    "- Inception Score: {results['wgan_gp']['evaluation_metrics']['inception_score']:.2f}\n",
    "- FID Score: {results['wgan_gp']['evaluation_metrics']['fid_score']:.2f}\n",
    "- Mode Collapse Ratio: {results['wgan_gp']['evaluation_metrics']['mode_collapse_ratio']:.4f}\n",
    "- Diversity Score: {results['wgan_gp']['evaluation_metrics']['diversity_score']:.2f}\n",
    "\n",
    "## Comparative Analysis\n",
    "\n",
    "### Training Stability\n",
    "- **Most Stable:** {results['comparative_analysis']['training_stability']['stability_winner']}\n",
    "- **DCGAN Stability:** {results['comparative_analysis']['training_stability']['dcgan_stability']:.4f}\n",
    "- **WGAN-GP Stability:** {results['comparative_analysis']['training_stability']['wgan_stability']:.4f}\n",
    "\n",
    "### Latent Space Quality\n",
    "- **DCGAN Correlation:** {results['comparative_analysis']['latent_space_quality']['dcgan_structure']['correlation']:.4f}\n",
    "- **WGAN-GP Correlation:** {results['comparative_analysis']['latent_space_quality']['wgan_structure']['correlation']:.4f}\n",
    "\n",
    "## Key Findings\n",
    "\n",
    "### 1. Training Dynamics\n",
    "- **WGAN-GP** demonstrates superior training stability with consistent loss convergence\n",
    "- **DCGAN** shows faster initial convergence but higher variance in later epochs\n",
    "- **Vanilla GAN** successfully learns 2D distributions but requires careful hyperparameter tuning\n",
    "\n",
    "### 2. Generation Quality\n",
    "- Both DCGAN and WGAN-GP produce visually coherent synthetic images\n",
    "- WGAN-GP shows better mode coverage and reduced collapse tendencies\n",
    "- DCGAN achieves competitive results with simpler architecture\n",
    "\n",
    "### 3. Latent Space Structure\n",
    "- Both models learn meaningful latent representations\n",
    "- Smooth interpolations demonstrate proper latent space organization\n",
    "- Random walks show diverse generation capabilities\n",
    "\n",
    "## Recommendations\n",
    "\n",
    "### Best Overall Model: {results['recommendations']['best_overall']}\n",
    "\n",
    "### Use Case Recommendations:\n",
    "- **Research & Stability:** {results['recommendations']['use_cases']['research_stability']}\n",
    "- **Quick Prototyping:** {results['recommendations']['use_cases']['quick_prototyping']}\n",
    "- **Educational Purposes:** {results['recommendations']['use_cases']['educational_purposes']}\n",
    "\n",
    "## Implementation Insights\n",
    "\n",
    "### Architecture Choices\n",
    "1. **Generator Design:** Transposed convolutions with batch normalization prove effective\n",
    "2. **Discriminator Design:** Strided convolutions with LeakyReLU provide stable gradients\n",
    "3. **Weight Initialization:** DCGAN initialization scheme improves convergence\n",
    "\n",
    "### Training Techniques\n",
    "1. **Learning Rates:** 0.0002 with Adam optimizer (Œ≤‚ÇÅ=0.5) works well for image GANs\n",
    "2. **Batch Size:** 64 provides good balance between stability and computational efficiency\n",
    "3. **Progressive Training:** Monitoring both networks prevents mode collapse\n",
    "\n",
    "### Evaluation Methods\n",
    "1. **Multiple Metrics:** Combination of IS, FID, and diversity measures provides comprehensive assessment\n",
    "2. **Latent Analysis:** Correlation between latent and image distances indicates quality\n",
    "3. **Visual Inspection:** Human evaluation remains important for generation quality\n",
    "\n",
    "## Future Directions\n",
    "\n",
    "### Potential Improvements\n",
    "1. **Progressive Growing:** Implement progressive GAN for higher resolution generation\n",
    "2. **Self-Attention:** Add attention mechanisms for better global coherence\n",
    "3. **Spectral Normalization:** Apply for improved training stability\n",
    "\n",
    "### Advanced Architectures\n",
    "1. **StyleGAN:** For high-quality, controllable generation\n",
    "2. **BigGAN:** For large-scale, diverse image synthesis\n",
    "3. **Conditional GANs:** For controlled generation with class labels\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This comprehensive analysis demonstrates the evolution of GAN architectures from theoretical foundations to practical applications. WGAN-GP emerges as the most robust choice for research applications, while DCGAN remains highly effective for rapid prototyping and educational purposes. The implementation provides a solid foundation for understanding adversarial training dynamics and serves as a stepping stone to more advanced generative models.\n",
    "\n",
    "## Technical Specifications\n",
    "\n",
    "**Environment Details:**\n",
    "- Device: {results['experiment_info']['device']}\n",
    "- PyTorch Version: {results['experiment_info']['pytorch_version']}\n",
    "- Total Training Time: Approximately 2-3 hours on modern GPU\n",
    "- Storage Requirements: ~500MB for models and results\n",
    "\n",
    "**Reproducibility:**\n",
    "- All random seeds set to 42 for deterministic results\n",
    "- Complete model checkpoints saved for future analysis\n",
    "- Comprehensive hyperparameter documentation included\n",
    "\n",
    "---\n",
    "\n",
    "*This report was automatically generated from the GAN Fundamentals notebook analysis.*\n",
    "\"\"\"\n",
    "    \n",
    "    with open(report_path, 'w') as f:\n",
    "        f.write(report_content)\n",
    "    \n",
    "    print(f\"   üìÑ Final report generated: {report_path}\")\n",
    "\n",
    "# Save comprehensive results and generate report\n",
    "print(\"\\nüéØ Finalizing Analysis and Saving Results:\")\n",
    "comprehensive_results = save_comprehensive_results()\n",
    "\n",
    "# Create a summary visualization of all generated files\n",
    "def create_project_summary():\n",
    "    \"\"\"Create a final summary of the entire project.\"\"\"\n",
    "    print(\"\\nüìã PROJECT SUMMARY\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Count generated files\n",
    "    model_files = list((notebook_results_dir / 'models').glob('*'))\n",
    "    analysis_files = list((notebook_results_dir / 'analysis').glob('*'))\n",
    "    image_files = list((notebook_results_dir / 'generated_images').glob('*'))\n",
    "    \n",
    "    print(f\"üìä Analysis Results:\")\n",
    "    print(f\"   ü§ñ Models Trained: 3 (Vanilla GAN, DCGAN, WGAN-GP)\")\n",
    "    print(f\"   üìà Training Epochs: {sum([len(vanilla_gan.history['epochs']), len(dcgan.history['epochs']), len(wgan_gp.history['epochs'])])}\")\n",
    "    print(f\"   üé® Images Generated: {len(image_files)}\")\n",
    "    print(f\"   üìä Analysis Plots: {len(analysis_files)}\")\n",
    "    print(f\"   üíæ Model Checkpoints: {len(model_files)}\")\n",
    "    \n",
    "    print(f\"\\nüèÜ Best Performing Model: {comprehensive_results['recommendations']['best_overall']}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ Output Structure:\")\n",
    "    print(f\"   üìÇ {notebook_results_dir}/\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ üìÇ models/ ({len(model_files)} files)\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ üìÇ analysis/ ({len(analysis_files)} files)\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ üìÇ generated_images/ ({len(image_files)} files)\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ üìÑ comprehensive_results.json\")\n",
    "    print(f\"   ‚îî‚îÄ‚îÄ üìÑ GAN_Fundamentals_Final_Report.md\")\n",
    "    \n",
    "    print(f\"\\nüéì Learning Objectives Achieved:\")\n",
    "    objectives = [\n",
    "        \"‚úÖ Mathematical foundations of adversarial training\",\n",
    "        \"‚úÖ Multiple GAN architectures implemented from scratch\", \n",
    "        \"‚úÖ Training dynamics analysis and stability assessment\",\n",
    "        \"‚úÖ Latent space exploration and interpolation\",\n",
    "        \"‚úÖ Comprehensive evaluation metrics implementation\",\n",
    "        \"‚úÖ Production-ready model checkpoints and documentation\"\n",
    "    ]\n",
    "    \n",
    "    for objective in objectives:\n",
    "        print(f\"   {objective}\")\n",
    "    \n",
    "    print(f\"\\nüöÄ Ready for Next Steps:\")\n",
    "    next_steps = [\n",
    "        \"Advanced GAN variants (StyleGAN, ProGAN, etc.)\",\n",
    "        \"Conditional generation and controllable synthesis\",\n",
    "        \"Real-world dataset application\",\n",
    "        \"Integration with downstream tasks\",\n",
    "        \"Production deployment considerations\"\n",
    "    ]\n",
    "    \n",
    "    for step in next_steps:\n",
    "        print(f\"   ‚Ä¢ {step}\")\n",
    "    \n",
    "    print(f\"\\n‚ú® GAN Fundamentals Implementation Complete! ‚ú®\")\n",
    "    print(f\"\\nTotal project artifacts: {len(model_files) + len(analysis_files) + len(image_files) + 2} files\")\n",
    "    print(f\"All results saved to: {notebook_results_dir}\")\n",
    "\n",
    "create_project_summary()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üéâ COMPREHENSIVE GAN FUNDAMENTALS ANALYSIS COMPLETED SUCCESSFULLY! üéâ\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nüéØ Key Achievements:\")\n",
    "print(\"   üìö Theoretical foundations mastered through interactive visualizations\")\n",
    "print(\"   üõ†Ô∏è Three complete GAN architectures implemented and trained\")\n",
    "print(\"   üìä Comprehensive comparative analysis with quantitative metrics\") \n",
    "print(\"   üî¨ Detailed latent space exploration and structure analysis\")\n",
    "print(\"   üìà Production-ready evaluation framework established\")\n",
    "print(\"   üíæ Complete model persistence and reproducibility achieved\")\n",
    "print(\"   üìÑ Professional documentation and reporting generated\")\n",
    "\n",
    "print(f\"\\nüöÄ This implementation provides a solid foundation for:\")\n",
    "print(\"   ‚Ä¢ Advanced generative model research\")\n",
    "print(\"   ‚Ä¢ Production image generation systems\") \n",
    "print(\"   ‚Ä¢ Educational GAN curriculum development\")\n",
    "print(\"   ‚Ä¢ Custom domain adaptation projects\")\n",
    "\n",
    "print(f\"\\nüìÅ Access your complete results at: {notebook_results_dir}\")\n",
    "print(\"Happy generating! üé®‚ú®\")\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
